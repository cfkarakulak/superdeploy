name: üîç Deploy SCRAPE VM

on:
  push:
    branches:
      - master
    paths:
      - 'deploy/compose/vm2-scrape/**'
  workflow_dispatch:

env:
  SCRAPE_HOST: ${{ vars.SCRAPE_INTERNAL_IP }}
  SCRAPE_USER: superdeploy
  COMPOSE_DIR: /opt/superdeploy/compose
  REPO_URL: http://${{ vars.CORE_EXTERNAL_IP }}:3001/cradexco/superdeploy-app.git
  WORKING_DIR: /opt/superdeploy

jobs:
  deploy:
    runs-on: self-hosted
    
    steps:
      - name: üì¶ Checkout code
        run: |
          # Initialize git if not exists
          if [ ! -d ${{ env.WORKING_DIR }}/.git ]; then
            cd ${{ env.WORKING_DIR }}
            git init
            git remote add origin ${{ env.REPO_URL }}
            git config user.email "runner@superdeploy.local"
            git config user.name "Superdeploy Runner"
          fi
          
          # Fetch and checkout
          cd ${{ env.WORKING_DIR }}
          git fetch origin ${{ github.ref_name }} || true
          git checkout ${{ github.ref_name }} || git checkout -b ${{ github.ref_name }} origin/${{ github.ref_name }}
          git pull origin ${{ github.ref_name }} || true
          echo "‚úÖ Code checked out: $(git rev-parse --short HEAD 2>/dev/null || echo 'initial')"

      - name: üîê Generate .env from Forgejo Secrets
        run: |
          cat > /tmp/scrape.env << EOF
          # Generated by Forgejo Actions on $(date)
          
          # Core Services Connection
          CORE_API_HOST=${{ vars.CORE_INTERNAL_IP }}
          CORE_API_PORT=${{ vars.CORE_API_PORT }}
          CORE_DB_HOST=${{ vars.CORE_INTERNAL_IP }}
          CORE_DB_PORT=${{ vars.CORE_DB_PORT }}
          CORE_DB_NAME=${{ vars.CORE_DB_NAME }}
          CORE_DB_USER=${{ vars.CORE_DB_USER }}
          CORE_DB_PASSWORD=${{ secrets.POSTGRES_PASSWORD }}
          
          # RabbitMQ Configuration
          RABBITMQ_HOST=${{ vars.CORE_INTERNAL_IP }}
          RABBITMQ_PORT=${{ vars.RABBITMQ_PORT }}
          RABBITMQ_USER=${{ vars.RABBITMQ_USER }}
          RABBITMQ_PASSWORD=${{ secrets.RABBITMQ_PASSWORD }}
          RABBITMQ_VHOST=${{ vars.RABBITMQ_VHOST }}
          RABBITMQ_QUEUE_NAME=${{ vars.RABBITMQ_QUEUE_NAME }}
          
          # Proxy Configuration
          PROXY_REGISTRY_HOST=${{ vars.CORE_INTERNAL_IP }}
          PROXY_REGISTRY_PORT=${{ vars.PROXY_REGISTRY_PORT }}
          PROXY_TIMEOUT=${{ vars.PROXY_TIMEOUT }}
          PROXY_RETRY_COUNT=${{ vars.PROXY_RETRY_COUNT }}
          PROXY_ROTATION_INTERVAL=${{ vars.PROXY_ROTATION_INTERVAL }}
          
          # Worker Configuration
          WORKER_CONCURRENCY=${{ vars.WORKER_CONCURRENCY }}
          WORKER_LOG_LEVEL=${{ vars.WORKER_LOG_LEVEL }}
          WORKER_NAME=${{ vars.WORKER_NAME }}
          PLAYWRIGHT_TIMEOUT=${{ vars.PLAYWRIGHT_TIMEOUT }}
          PLAYWRIGHT_HEADLESS=${{ vars.PLAYWRIGHT_HEADLESS }}
          
          # Scraping Configuration
          USER_AGENT=${{ vars.USER_AGENT }}
          MAX_RETRIES=${{ vars.MAX_RETRIES }}
          DOWNLOAD_DELAY=${{ vars.DOWNLOAD_DELAY }}
          CONCURRENT_REQUESTS=${{ vars.CONCURRENT_REQUESTS }}
          
          # Monitoring
          ENABLE_METRICS=${{ vars.ENABLE_METRICS }}
          SENTRY_DSN=${{ secrets.SENTRY_DSN }}
          EOF
          
          echo "‚úÖ .env file generated from secrets"

      - name: üì§ Copy files to SCRAPE VM
        run: |
          # Copy .env file
          scp -o StrictHostKeyChecking=no /tmp/scrape.env ${{ env.SCRAPE_USER }}@${{ env.SCRAPE_HOST }}:${{ env.COMPOSE_DIR }}/.env
          
          # Copy compose files
          scp -o StrictHostKeyChecking=no -r ${{ env.WORKING_DIR }}/deploy/compose/vm2-scrape/* ${{ env.SCRAPE_USER }}@${{ env.SCRAPE_HOST }}:${{ env.COMPOSE_DIR }}/
          
          echo "‚úÖ Files copied to SCRAPE VM"

      - name: üê≥ Deploy on SCRAPE VM
        run: |
          ssh -o StrictHostKeyChecking=no ${{ env.SCRAPE_USER }}@${{ env.SCRAPE_HOST }} << 'ENDSSH'
            cd ${{ env.COMPOSE_DIR }}
            
            # Pull latest images
            docker compose pull 2>&1 || echo "‚ö†Ô∏è  No pre-built images, will build locally"
            
            # Deploy services
            docker compose up -d --build
            
            echo "‚úÖ Services deployed on SCRAPE VM"
          ENDSSH

      - name: ‚è≥ Wait and check health
        run: |
          echo "‚è≥ Waiting 10s for services..."
          sleep 10

      - name: üìä Check service status
        run: |
          ssh -o StrictHostKeyChecking=no ${{ env.SCRAPE_USER }}@${{ env.SCRAPE_HOST }} << 'ENDSSH'
            cd ${{ env.COMPOSE_DIR }}
            
            echo "=== Container Status ==="
            docker compose ps
            
            echo ""
            echo "=== Worker Logs (last 20 lines) ==="
            docker compose logs --tail=20 worker || true
          ENDSSH

      - name: üßπ Cleanup
        run: |
          rm -f /tmp/scrape.env
          ssh -o StrictHostKeyChecking=no ${{ env.SCRAPE_USER }}@${{ env.SCRAPE_HOST }} \
            "docker image prune -f"
          echo "‚úÖ Cleanup complete"

      - name: üéâ Deployment Summary
        run: |
          echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
          echo "‚ïë  ‚úÖ SCRAPE VM Deployment Successful                          ‚ïë"
          echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
          echo ""
          echo "üîç SCRAPE VM: ${{ env.SCRAPE_HOST }}"
          echo "üìù Commit: ${{ github.sha }}"
          echo "üë§ Author: ${{ github.actor }}"
          echo "‚è∞ Time: $(date)"

