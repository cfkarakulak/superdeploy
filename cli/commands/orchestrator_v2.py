"""SuperDeploy CLI - Orchestrator command V2 (with improved logging and UX)"""

import click
import subprocess
import time
from pathlib import Path
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Prompt, Confirm
from cli.utils import get_project_root
from cli.logger import DeployLogger, run_with_progress

console = Console()


@click.group()
def orchestrator():
    """Manage global Forgejo orchestrator"""
    pass


@orchestrator.command()
@click.option(
    "--skip-terraform", is_flag=True, help="Skip Terraform (VM already exists)"
)
@click.option(
    "--preserve-ip", is_flag=True, help="Preserve static IP on destroy (for production)"
)
@click.option(
    "--addon",
    help="Deploy only specific addon(s), comma-separated (e.g. --addon monitoring,caddy)",
)
@click.option(
    "--tags", help="Run only specific Ansible tags (e.g. 'addons', 'foundation')"
)
@click.option(
    "--start-at-task",
    help="Resume Ansible from a specific task (e.g. 'Install Docker')",
)
@click.option(
    "--verbose", "-v", is_flag=True, help="Show all command output (default: clean UI with logs)"
)
def up(skip_terraform, preserve_ip, addon, tags, start_at_task, verbose):
    """Deploy orchestrator VM with Forgejo (runs Terraform + Ansible by default)"""
    
    if not verbose:
        console.print(
            Panel.fit(
                "[bold cyan]ðŸš€ Deploying Global Orchestrator[/bold cyan]\n\n"
                "[white]This will deploy a shared Forgejo instance for all projects[/white]",
                border_style="cyan",
            )
        )

    project_root = get_project_root()
    shared_dir = project_root / "shared"
    
    # Initialize logger
    with DeployLogger("orchestrator", "up", verbose=verbose) as logger:
        try:
            _deploy_orchestrator_v2(
                logger, project_root, shared_dir, skip_terraform, preserve_ip,
                addon, tags, start_at_task, verbose
            )
            
            if not verbose:
                console.print("\n[bold green]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[/bold green]")
                console.print("[bold green]âœ… Orchestrator Deployed![/bold green]")
                console.print("[bold green]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[/bold green]\n")
                
        except Exception as e:
            logger.log_error(str(e), context="Orchestrator deployment failed")
            raise SystemExit(1)


def _deploy_orchestrator_v2(
    logger, project_root, shared_dir, skip_terraform, preserve_ip,
    addon, tags, start_at_task, verbose
):
    """Internal function for orchestrator deployment with logging"""
    
    # Load orchestrator config
    logger.step("Loading orchestrator configuration")
    from cli.core.orchestrator_loader import OrchestratorLoader
    
    orchestrator_loader = OrchestratorLoader(shared_dir)
    
    try:
        orch_config = orchestrator_loader.load()
        logger.success("Configuration loaded")
    except FileNotFoundError as e:
        logger.log_error(str(e), context="Orchestrator config not found")
        raise SystemExit(1)
    
    # Generate and save secrets
    logger.step("Checking secrets")
    import secrets as secrets_module
    
    orchestrator_dir = shared_dir / "orchestrator"
    orchestrator_dir.mkdir(parents=True, exist_ok=True)
    
    env_file = orchestrator_dir / ".env"
    
    if env_file.exists():
        logger.success("Using existing secrets from .env")
        logger.log("Secrets file exists, skipping generation")
    else:
        logger.log("Generating new secrets")
        project_secrets = {
            "FORGEJO_ADMIN_PASSWORD": secrets_module.token_urlsafe(32),
            "FORGEJO_DB_PASSWORD": secrets_module.token_urlsafe(32),
            "FORGEJO_SECRET_KEY": secrets_module.token_urlsafe(48),
            "FORGEJO_INTERNAL_TOKEN": secrets_module.token_urlsafe(79),
            "GRAFANA_ADMIN_PASSWORD": secrets_module.token_urlsafe(32),
        }
        
        env_content = """# =============================================================================
# Orchestrator Secrets
# =============================================================================
# Auto-generated by: superdeploy orchestrator up
# DO NOT COMMIT THIS FILE TO GIT!
# =============================================================================

# Forgejo Admin Password
FORGEJO_ADMIN_PASSWORD={FORGEJO_ADMIN_PASSWORD}

# Forgejo Database Password
FORGEJO_DB_PASSWORD={FORGEJO_DB_PASSWORD}

# Forgejo Secret Key (for encryption)
FORGEJO_SECRET_KEY={FORGEJO_SECRET_KEY}

# Forgejo Internal Token (for API)
FORGEJO_INTERNAL_TOKEN={FORGEJO_INTERNAL_TOKEN}

# Monitoring Addon Secrets
GRAFANA_ADMIN_PASSWORD={GRAFANA_ADMIN_PASSWORD}

# Grafana SMTP Password (optional - for email alerts)
# Set this manually if you enable SMTP in config.yml
# GRAFANA_SMTP_PASSWORD=your-smtp-password-here
""".format(**project_secrets)
        
        with open(env_file, "w") as f:
            f.write(env_content)
        
        env_file.chmod(0o600)
        logger.success("Secrets generated and saved")
    
    # Get GCP config
    gcp_config = orch_config.config.get("gcp", {})
    ssh_config = orch_config.config.get("ssh", {})
    
    gcp_project_id = gcp_config.get("project_id")
    if not gcp_project_id:
        logger.log_error("gcp.project_id not set in shared/orchestrator/config.yml")
        raise SystemExit(1)
    
    ssh_key_path = ssh_config.get("public_key_path", "~/.ssh/superdeploy_deploy.pub")
    
    # Terraform
    if not skip_terraform:
        logger.step("Provisioning VM with Terraform")
        
        from cli.terraform_utils import (
            terraform_init,
            terraform_apply,
            select_workspace,
            get_terraform_outputs,
        )
        
        # Init
        logger.log("Running terraform init")
        returncode, stdout, stderr = run_with_progress(
            logger,
            "cd shared/terraform && terraform init -upgrade",
            "Initializing Terraform",
            cwd=project_root
        )
        
        if returncode != 0:
            logger.log_error("Terraform init failed", context=stderr)
            raise SystemExit(1)
        
        # Generate tfvars
        logger.log("Generating terraform variables")
        tfvars = orch_config.to_terraform_vars(gcp_project_id, ssh_key_path)
        
        tfvars_file = project_root / "shared" / "terraform" / "orchestrator.auto.tfvars.json"
        import json
        with open(tfvars_file, "w") as f:
            json.dump(tfvars, f, indent=2)
        
        logger.log(f"Terraform vars saved to: {tfvars_file}")
        
        # Select workspace
        logger.log("Selecting terraform workspace: orchestrator")
        returncode, stdout, stderr = run_with_progress(
            logger,
            "cd shared/terraform && terraform workspace select orchestrator || terraform workspace new orchestrator",
            "Selecting workspace",
            cwd=project_root
        )
        
        if returncode != 0:
            logger.log_error("Workspace selection failed", context=stderr)
            raise SystemExit(1)
        
        # Apply
        logger.log("Running terraform apply")
        apply_cmd = f"cd shared/terraform && terraform apply -auto-approve"
        
        if preserve_ip:
            logger.log("Preserve IP mode enabled")
        
        returncode, stdout, stderr = run_with_progress(
            logger,
            apply_cmd,
            "Provisioning infrastructure (this may take 2-3 minutes)",
            cwd=project_root
        )
        
        if returncode != 0:
            logger.log_error("Terraform apply failed", context=stderr)
            raise SystemExit(1)
        
        logger.success("VM provisioned successfully")
        
        # Get outputs
        logger.log("Extracting VM IP from terraform outputs")
        returncode, stdout, stderr = run_with_progress(
            logger,
            "cd shared/terraform && terraform output -json",
            "Getting VM details",
            cwd=project_root
        )
        
        if returncode != 0:
            logger.log_error("Failed to get terraform outputs", context=stderr)
            raise SystemExit(1)
        
        import json
        outputs = json.loads(stdout)
        orchestrator_ip = outputs.get("vm_public_ips", {}).get("value", {}).get("main-0")
        
        if not orchestrator_ip:
            logger.log_error("Could not find orchestrator IP in terraform outputs")
            raise SystemExit(1)
        
        logger.log(f"Orchestrator IP: {orchestrator_ip}")
        
        # Save IP to .env
        orch_config.mark_deployed(orchestrator_ip)
        logger.success(f"Orchestrator IP saved: {orchestrator_ip}")
        
        # Wait for SSH
        logger.step("Waiting for VM to be ready")
        ssh_key = ssh_config.get("key_path", "~/.ssh/superdeploy_deploy")
        ssh_user = ssh_config.get("user", "superdeploy")
        
        max_attempts = 18
        for attempt in range(1, max_attempts + 1):
            logger.log(f"SSH check attempt {attempt}/{max_attempts}")
            
            check_cmd = f"ssh -i {ssh_key} -o ConnectTimeout=5 -o StrictHostKeyChecking=no -o BatchMode=yes {ssh_user}@{orchestrator_ip} 'sudo -n whoami' 2>&1"
            result = subprocess.run(check_cmd, shell=True, capture_output=True, text=True, timeout=10)
            
            logger.log_output(result.stdout, "stdout")
            logger.log_output(result.stderr, "stderr")
            
            if result.returncode == 0 and "root" in result.stdout:
                logger.success("VM is ready and accessible")
                break
            
            if attempt < max_attempts:
                logger.log("VM not ready yet, waiting 10 seconds...")
                time.sleep(10)
        else:
            logger.warning("VM may not be fully ready, continuing anyway...")
        
        # Clean SSH known_hosts
        logger.log("Cleaning SSH known_hosts")
        subprocess.run(["ssh-keygen", "-R", orchestrator_ip], capture_output=True)
        logger.log("SSH known_hosts cleaned")
    
    else:
        logger.step("Skipping Terraform (--skip-terraform)")
        orchestrator_ip = orch_config.get_ip()
        if not orchestrator_ip:
            logger.log_error("Orchestrator IP not found. Deploy with Terraform first.")
            raise SystemExit(1)
        logger.log(f"Using existing orchestrator IP: {orchestrator_ip}")
    
    # Ansible
    logger.step("Configuring services with Ansible")
    
    from cli.ansible_utils import build_ansible_command
    
    ansible_dir = project_root / "shared" / "ansible"
    
    # Prepare ansible vars
    ansible_vars = orch_config.to_ansible_vars()
    
    # Add orchestrator IP
    ansible_env_vars = {
        "superdeploy_root": str(project_root),
        "orchestrator_ip": orchestrator_ip,
    }
    
    # Build ansible command
    ansible_tags = tags if tags else "foundation,addons"
    
    logger.log(f"Running ansible with tags: {ansible_tags}")
    if start_at_task:
        logger.log(f"Resuming from task: {start_at_task}")
    
    ansible_cmd = build_ansible_command(
        ansible_dir=ansible_dir,
        project_root=project_root,
        project_config=ansible_vars,
        env_vars=ansible_env_vars,
        tags=ansible_tags,
        project_name="orchestrator",
        ask_become_pass=False,
        start_at_task=start_at_task,
    )
    
    logger.log_command(ansible_cmd)
    
    # Run ansible
    if verbose:
        # Verbose mode: show output directly
        result = subprocess.run(ansible_cmd, shell=True, cwd=str(project_root))
        if result.returncode != 0:
            logger.log_error("Ansible configuration failed")
            raise SystemExit(1)
    else:
        # Non-verbose: capture and log
        from rich.live import Live
        from rich.spinner import Spinner
        
        with Live(
            Spinner("dots", text="[cyan]Configuring services (this may take 5-10 minutes)...[/cyan]"),
            console=console,
            refresh_per_second=10,
        ) as live:
            result = subprocess.run(
                ansible_cmd,
                shell=True,
                cwd=str(project_root),
                capture_output=True,
                text=True
            )
            
            # Log output
            logger.log_output(result.stdout, "stdout")
            logger.log_output(result.stderr, "stderr")
            
            if result.returncode == 0:
                live.update("[green]âœ“ Services configured[/green]")
            else:
                live.update("[red]âœ— Configuration failed[/red]")
        
        if result.returncode != 0:
            logger.log_error("Ansible configuration failed", context="Check logs for details")
            raise SystemExit(1)
    
    logger.success("Services configured successfully")
    
    # Display info
    if not verbose:
        console.print(f"\n[cyan]ðŸ“ Orchestrator IP:[/cyan] {orchestrator_ip}")
        console.print(f"[cyan]ðŸŒ Forgejo:[/cyan] http://{orchestrator_ip}:3001")
        console.print(f"[cyan]ðŸ“Š Grafana:[/cyan] http://{orchestrator_ip}:3000")
        console.print(f"[cyan]ðŸ“ˆ Prometheus:[/cyan] http://{orchestrator_ip}:9090")
