"""
Generate deployment files from project config
"""

import click
import secrets
from pathlib import Path
from rich.console import Console

console = Console()


@click.command()
@click.option("--project", "-p", required=True, help="Project name")
def generate(project):
    """
    Generate deployment files from project.yml using addon system

    Example:
        superdeploy generate -p acme
    """
    console.print(
        f"\n[bold cyan]üîß Generating deployment files for: {project}[/bold cyan]"
    )
    console.print("‚îÅ" * 40)

    from cli.utils import get_project_root
    from cli.core.addon_loader import AddonLoader, AddonNotFoundError
    from cli.core.template_merger import TemplateMerger
    from cli.core.validator import ValidationEngine, ValidationException
    from cli.core.config_loader import ConfigLoader

    project_root = get_project_root()
    projects_dir = project_root / "projects"
    project_dir = projects_dir / project

    # Load config using ConfigLoader
    config_loader = ConfigLoader(projects_dir)

    try:
        project_config = config_loader.load_project(project)
        console.print(f"[dim]‚úì Loaded config: {project_dir}/project.yml[/dim]")
    except FileNotFoundError as e:
        console.print(f"[red]‚ùå {e}[/red]")
        return
    except ValueError as e:
        console.print(f"[red]‚ùå Invalid configuration: {e}[/red]")
        return

    # Get raw config for backward compatibility with addon system
    config = project_config.raw_config

    # Validate config
    if not config.get("apps"):
        console.print("[red]‚ùå No apps defined in config![/red]")
        return

    # Initialize addon system
    addons_dir = project_root / "addons"
    addon_loader = AddonLoader(addons_dir)
    template_merger = TemplateMerger()
    validator = ValidationEngine(project_root / "projects")

    # Load addons for this project
    console.print("\n[dim]Loading addons...[/dim]")
    try:
        addons = addon_loader.load_addons_for_project(config)
        console.print(
            f"[dim]‚úì Loaded {len(addons)} addon(s): {', '.join(addons.keys())}[/dim]"
        )
    except AddonNotFoundError as e:
        console.print(f"[red]‚ùå {e}[/red]")
        return
    except Exception as e:
        console.print(f"[red]‚ùå Error loading addons: {e}[/red]")
        return

    # Validate configuration
    console.print("\n[dim]Validating configuration...[/dim]")
    try:
        validator.validate_and_raise(config, addons, project)
        console.print("[dim]‚úì Validation passed[/dim]")
    except ValidationException as e:
        console.print(f"\n[red]{e}[/red]")
        console.print("\n[yellow]‚ö† Fix validation errors before proceeding[/yellow]")
        return

    # Create compose directory
    compose_dir = project_dir / "compose"
    compose_dir.mkdir(parents=True, exist_ok=True)

    # Generate .env file if not exists
    env_file = project_dir / ".env"
    if not env_file.exists():
        console.print("\n[dim]Generating .env file...[/dim]")
        passwords = generate_passwords(addons)

        env_content = f"""# =============================================================================
# {config.get("project")} - Environment Variables
# =============================================================================
# Auto-generated by: superdeploy generate -p {config.get("project")}
# DO NOT COMMIT THIS FILE TO GIT!
# =============================================================================

# Docker credentials (read from shared/config/.env)
# DOCKER_REGISTRY, DOCKER_ORG, DOCKER_USERNAME, DOCKER_TOKEN are managed globally

# GitHub Token
GITHUB_TOKEN=your-github-token  # Get from GitHub: https://github.com/settings/tokens

# Forgejo PAT (read from shared/orchestrator/.env)
# FORGEJO_PAT is managed globally by orchestrator

# Generated Passwords (from addons)
"""

        # Add ONLY secrets to .env (passwords, tokens, generated values)
        for addon_name, addon_passwords in passwords.items():
            env_content += f"\n# {addon_name.title()} Secrets\n"
            for var_name, var_data in addon_passwords.items():
                if isinstance(var_data, dict):
                    value = var_data.get("value", "")
                    description = var_data.get("description", "")
                    env_content += f"{var_name}={value}  # {description}\n"
                else:
                    env_content += f"{var_name}={var_data}\n"

        with open(env_file, "w") as f:
            f.write(env_content)

        # Set restrictive permissions
        env_file.chmod(0o600)

        console.print(f"  [green]‚úì[/green] Generated: {env_file}")

        # Show summary of generated passwords
        total_passwords = sum(
            len(addon_passwords) for addon_passwords in passwords.values()
        )
        console.print(
            f"  [dim]Generated {total_passwords} password(s) for {len(passwords)} addon(s)[/dim]"
        )
        console.print("  [yellow]‚ö†[/yellow] Remember to edit .env and add your tokens!")

    # Generate docker-compose.core.yml using addon system
    console.print("\n[dim]Generating docker-compose files...[/dim]")
    compose_content = template_merger.merge_compose(addons, config)
    (compose_dir / "docker-compose.core.yml").write_text(compose_content)
    console.print(
        f"  [green]‚úì[/green] Generated: {compose_dir}/docker-compose.core.yml"
    )

    # Generate docker-compose.apps.yml
    generate_docker_compose_apps(config, compose_dir)
    console.print(
        f"  [green]‚úì[/green] Generated: {compose_dir}/docker-compose.apps.yml"
    )

    # Generate app deployment files
    console.print("\n[dim]Generating app deployment files...[/dim]")
    for app_name, app_config in config["apps"].items():
        app_path = Path(app_config["path"]).expanduser().resolve()

        if not app_path.exists():
            console.print(
                f"  [yellow]‚ö†[/yellow] {app_name}: Path not found: {app_path}"
            )
            continue

        # Generate .env.superdeploy using addon system
        env_content = template_merger.merge_env(addons, config)
        (app_path / ".env.superdeploy").write_text(env_content)

        # Generate workflow using addon system
        workflow_dir = app_path / ".github" / "workflows"
        workflow_dir.mkdir(parents=True, exist_ok=True)
        workflow_content = generate_workflow(config, app_name, addons, template_merger)
        (workflow_dir / "deploy.yml").write_text(workflow_content)

        console.print(f"  [green]‚úì[/green] {app_name}: {app_path}")

    console.print("\n[green]‚úÖ Generation complete![/green]")
    console.print("\n[bold]üìù Next steps:[/bold]")
    console.print("\n1. Review generated files")
    console.print("\n2. Commit app deployment files:")
    console.print("   [dim]cd <app-repo>[/dim]")
    console.print("   [dim]git add .env.superdeploy .github/[/dim]")
    console.print('   [dim]git commit -m "Add SuperDeploy config"[/dim]')
    console.print("\n3. Deploy infrastructure:")
    console.print(f"   [cyan]superdeploy up -p {project}[/cyan]")


def _build_github_secrets_documentation(passwords, config):
    """
    Build documentation for GitHub secrets that need to be set.

    Args:
        passwords: Dictionary of generated passwords by addon
        config: Project configuration dictionary

    Returns:
        Dictionary with instructions for setting GitHub secrets
    """
    project_name = config.get("project")
    github_org = config.get("github", {}).get("organization", f"{project_name}io")
    apps = config.get("apps", {})

    docs = {
        "instructions": "Use GitHub CLI to set these secrets for each app repository",
        "example_commands": [],
        "secrets_by_addon": {},
    }

    # Generate example commands for first app
    if apps:
        first_app = list(apps.keys())[0]
        docs["example_commands"].append(f"# Example for {first_app} repository:")

        for addon_name, addon_passwords in passwords.items():
            for var_name, var_info in addon_passwords.items():
                value = var_info["value"]
                description = var_info.get("description", "")

                docs["example_commands"].append(
                    f'gh secret set {var_name} -b "{value}" -R {github_org}/{first_app}  # {description}'
                )

        docs["example_commands"].append("")
        docs["example_commands"].append("# Repeat for other app repositories:")
        for app_name in list(apps.keys())[1:]:
            docs["example_commands"].append(f"# - {github_org}/{app_name}")

    # Document secrets by addon
    for addon_name, addon_passwords in passwords.items():
        docs["secrets_by_addon"][addon_name] = {
            "secrets": list(addon_passwords.keys()),
            "values": {
                var_name: {
                    "value": var_info["value"],
                    "description": var_info.get("description", ""),
                }
                for var_name, var_info in addon_passwords.items()
            },
        }

    return docs


def generate_passwords(addons):
    """
    Generate passwords for addons that require them.

    Only generates passwords for environment variables that have both:
    - secret: true
    - generate: true

    Args:
        addons: Dictionary of loaded addons

    Returns:
        Dictionary with addon context and generated passwords
        Format: {
            'addon_name': {
                'VAR_NAME': 'generated_password',
                ...
            }
        }
    """
    passwords = {}

    for addon_name, addon in addons.items():
        addon_passwords = {}

        # Check env_vars in metadata for password fields
        env_vars = addon.metadata.get("env_vars", [])

        for env_var in env_vars:
            if isinstance(env_var, dict):
                # Check if this is a secret that should be generated
                if env_var.get("secret") and env_var.get("generate"):
                    var_name = env_var.get("name")
                    description = env_var.get("description", "")

                    if var_name:
                        # Generate secure password (32 bytes = 43 characters in base64)
                        addon_passwords[var_name] = {
                            "value": secrets.token_urlsafe(32),
                            "description": description,
                        }

        # Only add addon to passwords if it has any generated passwords
        if addon_passwords:
            passwords[addon_name] = addon_passwords

    return passwords


def generate_docker_compose_apps(config, compose_dir):
    """
    Generate docker-compose.apps.yml for application services.

    Args:
        config: Project configuration dictionary
        compose_dir: Directory to write compose file to
    """
    project_name = config["project"]
    apps = config.get("apps", {})

    lines = [
        f"# App Services for {project_name}",
        "# Auto-generated by: superdeploy generate",
        "",
        "networks:",
        f"  {project_name}-network:",
        f"    name: {project_name}-network",
        "    external: true",
        "",
        "services:",
    ]

    for app_name, app_config in apps.items():
        # Support both simple port and external_port/internal_port
        external_port = app_config.get("external_port")
        internal_port = app_config.get("internal_port")
        
        # Fallback to simple port if external/internal not specified
        if external_port is None or internal_port is None:
            port = app_config.get("port", 8000)
            external_port = port
            internal_port = port
        
        tag_var = f"{app_name.upper()}_TAG"  # e.g., API_TAG
        lines.extend(
            [
                "",
                f"  {app_name}:",
                f"    image: ${{DOCKER_REGISTRY:-docker.io}}/${{DOCKER_ORG}}/{app_name}:" + "${" + tag_var + "}",
                f"    container_name: {project_name}-{app_name}",
                "    restart: unless-stopped",
                "    ports:",
                f'      - "{external_port}:{internal_port}"',
                "    env_file:",
                f"      - .env.{app_name}",
                "    networks:",
                f"      - {project_name}-network",
            ]
        )

    (compose_dir / "docker-compose.apps.yml").write_text("\n".join(lines))


def generate_workflow(config, app_name, addons, template_merger):
    """
    Generate GitHub Actions workflow using addon system.
    """
    project_name = config["project"]
    docker_org = config.get("docker", {}).get("organization", project_name)

    # Build env section from addons (each line should already look like: "  FOO: ${{ secrets.FOO }}")
    env_vars = template_merger.merge_workflow_env(addons)
    env_section = "\n".join(env_vars)

    # ONLY interpolate docker_org/app_name here. Keep GA expressions escaped with quadruple braces.
    workflow = """name: Build and Deploy

on:
  push:
    branches:
      - production
  workflow_dispatch:

env:
  REGISTRY: docker.io
  IMAGE_NAME: {docker_org}/{app_name}

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{{{ secrets.DOCKER_USERNAME }}}}
          password: ${{{{ secrets.DOCKER_TOKEN }}}}
      
      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{{{ env.REGISTRY }}}}/${{{{ env.IMAGE_NAME }}}}:${{{{ github.sha }}}}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Install age
        run: |
          curl -sL https://github.com/FiloSottile/age/releases/download/v1.1.1/age-v1.1.1-linux-amd64.tar.gz | tar xz
          sudo mv age/age /usr/local/bin/
          rm -rf age
      
      - name: Prepare environment bundle
        id: env_bundle""".format(docker_org=docker_org, app_name=app_name)

    if env_section:
        # DO NOT format this block; just append so inner ${ { ‚Ä¶ } } stays intact.
        workflow += "\n        env:\n" + env_section + "\n"

    workflow += r"""
        run: |
          # Merge .env files using shell
          cp .env /tmp/app.env 2>/dev/null || touch /tmp/app.env
          
          if [ -f .env.superdeploy ]; then
            while IFS='=' read -r key value || [ -n "$key" ]; do
              # Skip empty lines and comments
              [ -z "$key" ] && continue
              [[ "$key" =~ ^[[:space:]]*# ]] && continue
              
              # Expand ${VAR} syntax
              if [[ "$value" =~ ^\$\{([^}]+)\}$ ]]; then
                var_name="${BASH_REMATCH[1]}"
                value="${!var_name}"
              fi
              
              # Update or append to merged env
              if grep -q "^${key}=" /tmp/app.env 2>/dev/null; then
                sed -i.bak "s|^${key}=.*|${key}=${value}|" /tmp/app.env && rm -f /tmp/app.env.bak
              else
                echo "${key}=${value}" >> /tmp/app.env
              fi
            done < .env.superdeploy
          fi
          
          # Encrypt with age public key
          cat /tmp/app.env | age -r "${{ secrets.AGE_PUBLIC_KEY }}" | base64 -w 0 > /tmp/encrypted.txt
          echo "encrypted=$(cat /tmp/encrypted.txt)" >> "$GITHUB_OUTPUT"
          rm -f /tmp/app.env /tmp/encrypted.txt
      
      - name: Connectivity check to Forgejo
        env:
          FORGEJO_BASE_URL: ${{ secrets.FORGEJO_BASE_URL }}
        run: |
          set -euo pipefail
          echo "Checking reachability of $FORGEJO_BASE_URL ..."
          # Try to reach Forgejo (5 second timeout)
          if curl -sS -I --max-time 5 --connect-timeout 5 "$FORGEJO_BASE_URL" 2>/dev/null; then
            echo "‚úì Forgejo reachable"
          else
            echo "::warning::Forgejo base URL not reachable from GitHub runner."
            echo "This is expected if Forgejo is behind firewall/VPN."
            echo "Deployment will continue but may fail if Forgejo API is not accessible."
            echo "Tip: Check firewall rules, use public IP with port 443, or use self-hosted runner."
          fi
      
      - name: Trigger Forgejo deployment
        env:
          FORGEJO_PAT: ${{ secrets.FORGEJO_PAT }}
          FORGEJO_BASE_URL: ${{ secrets.FORGEJO_BASE_URL }}
          FORGEJO_ORG: ${{ secrets.FORGEJO_ORG }}
        run: |
          set -euo pipefail
          
          # Debug: Show PAT prefix (first 10 chars only)
          echo "PAT prefix: ${FORGEJO_PAT:0:10}..."
          echo "Base URL: $FORGEJO_BASE_URL"
          echo "Org: $FORGEJO_ORG"
          
          # Test PAT first
          echo "Testing PAT..."
          TEST_RESPONSE=$(curl -sS -i -H "Authorization: token $FORGEJO_PAT" "$FORGEJO_BASE_URL/api/v1/user")
          TEST_CODE=$(echo "$TEST_RESPONSE" | head -n1 | cut -d' ' -f2)
          echo "PAT test result: HTTP $TEST_CODE"
          
          if [[ "$TEST_CODE" != "200" ]]; then
            echo "::error::PAT is invalid (HTTP $TEST_CODE)"
            echo "$TEST_RESPONSE" | tail -5
            exit 1
          fi
          
          # Build JSON payload and trigger deployment
          RESPONSE=$(curl -sS -i -X POST \
            --max-time 30 \
            --connect-timeout 10 \
            -H "Authorization: token $FORGEJO_PAT" \
            -H "Content-Type: application/json" \
            -d "{\"ref\":\"master\",\"inputs\":{\"project\":\"%(project_name)s\",\"service\":\"%(app_name)s\",\"image\":\"${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\",\"env_bundle\":\"${{ steps.env_bundle.outputs.encrypted }}\",\"git_sha\":\"${{ github.sha }}\"}}" \
            "$FORGEJO_BASE_URL/api/v1/repos/$FORGEJO_ORG/superdeploy/actions/workflows/project-deploy.yml/dispatches")
          
          HTTP_CODE=$(echo "$RESPONSE" | head -n1 | cut -d' ' -f2)
          BODY=$(echo "$RESPONSE" | tail -n1)
          
          echo "Response: $BODY"
          echo "HTTP Status: $HTTP_CODE"
          
          if [[ "$HTTP_CODE" =~ ^2[0-9][0-9]$ ]]; then
            echo "‚úì Deployment triggered successfully"
          else
            echo "::error::Failed to trigger Forgejo deployment (HTTP $HTTP_CODE)"
            echo "::error::Response: $BODY"
            exit 1
          fi
"""

    # Safely inject project/app into the JSON literal placeholders (not GA syntax)
    workflow = workflow.replace("%(project_name)s", project_name).replace("%(app_name)s", app_name)
    return workflow


if __name__ == "__main__":
    generate()