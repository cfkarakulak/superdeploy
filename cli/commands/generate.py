"""
Generate deployment files from project config
"""

import click
import secrets
from pathlib import Path
from rich.console import Console
from cli.ui_components import show_header

console = Console()


@click.command()
@click.option("--project", "-p", required=True, help="Project name")
def generate(project):
    """
    Generate deployment files from project.yml using addon system

    Example:
        superdeploy generate -p acme
    """
    show_header(
        title="Generate Deployment Files",
        project=project,
        subtitle="Building from project.yml using addon system",
        console=console,
    )

    from cli.utils import get_project_root
    from cli.core.addon_loader import AddonLoader, AddonNotFoundError
    from cli.core.template_merger import TemplateMerger
    from cli.core.validator import ValidationEngine, ValidationException
    from cli.core.config_loader import ConfigLoader

    project_root = get_project_root()
    projects_dir = project_root / "projects"
    project_dir = projects_dir / project

    # Load config using ConfigLoader
    config_loader = ConfigLoader(projects_dir)

    try:
        project_config = config_loader.load_project(project)
        console.print(f"[dim]‚úì Loaded config: {project_dir}/project.yml[/dim]")
    except FileNotFoundError as e:
        console.print(f"[red]‚ùå {e}[/red]")
        return
    except ValueError as e:
        console.print(f"[red]‚ùå Invalid configuration: {e}[/red]")
        return

    # Get raw config for backward compatibility with addon system
    config = project_config.raw_config

    # Validate config
    if not config.get("apps"):
        console.print("[red]‚ùå No apps defined in config![/red]")
        return

    # Initialize addon system
    addons_dir = project_root / "addons"
    addon_loader = AddonLoader(addons_dir)
    template_merger = TemplateMerger()
    validator = ValidationEngine(project_root / "projects")

    # Load addons for this project
    console.print("\n[dim]Loading addons...[/dim]")
    try:
        addons = addon_loader.load_addons_for_project(config)
        console.print(
            f"[dim]‚úì Loaded {len(addons)} addon(s): {', '.join(addons.keys())}[/dim]"
        )
    except AddonNotFoundError as e:
        console.print(f"[red]‚ùå {e}[/red]")
        return
    except Exception as e:
        console.print(f"[red]‚ùå Error loading addons: {e}[/red]")
        return

    # Validate configuration
    console.print("\n[dim]Validating configuration...[/dim]")
    try:
        validator.validate_and_raise(config, addons, project)
        console.print("[dim]‚úì Validation passed[/dim]")
    except ValidationException as e:
        console.print(f"\n[red]{e}[/red]")
        console.print("\n[yellow]‚ö† Fix validation errors before proceeding[/yellow]")
        return

    # Create compose directory
    compose_dir = project_dir / "compose"
    compose_dir.mkdir(parents=True, exist_ok=True)

    # Generate .env file if not exists
    env_file = project_dir / ".env"
    if not env_file.exists():
        console.print("\n[dim]Generating .env file...[/dim]")
        passwords = generate_passwords(addons)

        # Extract project name from nested structure
        project_info = config.get("project", {})
        if isinstance(project_info, dict):
            project_name = project_info.get("name", "project")
        else:
            project_name = str(project_info)

        env_content = f"""# =============================================================================
# {project_name} - Environment Variables
# =============================================================================
# Auto-generated by: superdeploy generate -p {project_name}
# DO NOT COMMIT THIS FILE TO GIT!
# =============================================================================
# Note: ALERT_EMAIL and SMTP_USER are automatically added to .env.superdeploy
#       from project.yml notifications section
# =============================================================================

# Docker Registry Credentials (registry is always docker.io)
DOCKER_ORG=your-docker-org  # Your Docker Hub organization
DOCKER_USERNAME=your-docker-username  # Your Docker Hub username
DOCKER_TOKEN=  # Get from: https://hub.docker.com/settings/security

# GitHub Token
GITHUB_TOKEN=your-github-token  # Get from GitHub: https://github.com/settings/tokens

# SMTP Password (for email notifications)
SMTP_PASSWORD=  # SMTP password or app-specific password

# Generated Passwords (from addons)
"""

        # Add ONLY secrets to .env (passwords, tokens, generated values)
        for addon_name, addon_passwords in passwords.items():
            env_content += f"\n# {addon_name.title()} Secrets\n"
            for var_name, var_data in addon_passwords.items():
                if isinstance(var_data, dict):
                    value = var_data.get("value", "")
                    description = var_data.get("description", "")
                    env_content += f"{var_name}={value}  # {description}\n"
                else:
                    env_content += f"{var_name}={var_data}\n"

        with open(env_file, "w") as f:
            f.write(env_content)

        # Set restrictive permissions
        env_file.chmod(0o600)

        console.print(f"  [green]‚úì[/green] Generated: {env_file}")

        # Show summary of generated passwords
        total_passwords = sum(
            len(addon_passwords) for addon_passwords in passwords.values()
        )
        console.print(
            f"  [dim]Generated {total_passwords} password(s) for {len(passwords)} addon(s)[/dim]"
        )
        console.print("  [yellow]‚ö†[/yellow] Remember to edit .env and add your tokens!")

    # Generate docker-compose.core.yml using addon system
    console.print("\n[dim]Generating docker-compose files...[/dim]")
    compose_content = template_merger.merge_compose(addons, config)
    (compose_dir / "docker-compose.core.yml").write_text(compose_content)
    console.print(
        f"  [green]‚úì[/green] Generated: {compose_dir}/docker-compose.core.yml"
    )

    # Generate docker-compose.apps.yml
    generate_docker_compose_apps(config, compose_dir)
    console.print(
        f"  [green]‚úì[/green] Generated: {compose_dir}/docker-compose.apps.yml"
    )

    # Generate app deployment files
    console.print("\n[dim]Generating app deployment files...[/dim]")
    for app_name, app_config in config["apps"].items():
        app_path = Path(app_config["path"]).expanduser().resolve()

        if not app_path.exists():
            console.print(
                f"  [yellow]‚ö†[/yellow] {app_name}: Path not found: {app_path}"
            )
            continue

        # Generate .env.superdeploy using addon system
        env_content = template_merger.merge_env(addons, config)
        (app_path / ".env.superdeploy").write_text(env_content)

        # Generate workflow using addon system
        workflow_dir = app_path / ".github" / "workflows"
        workflow_dir.mkdir(parents=True, exist_ok=True)
        workflow_content = generate_workflow(config, app_name, addons, template_merger)
        (workflow_dir / "deploy.yml").write_text(workflow_content)

        console.print(f"  [green]‚úì[/green] {app_name}: {app_path}")

    # Generate Forgejo workflows for project
    console.print("\n[bold cyan]üìã Generating Forgejo workflows...[/bold cyan]")
    # Forgejo only recognizes workflows in .forgejo/workflows/
    forgejo_workflows_dir = (
        project_root / ".forgejo" / "workflows" / "projects" / project
    )
    forgejo_workflows_dir.mkdir(parents=True, exist_ok=True)

    for app_name in config.get("apps", {}).keys():
        forgejo_workflow_content = generate_forgejo_workflow(config, app_name)
        (forgejo_workflows_dir / f"deploy-{app_name}.yml").write_text(
            forgejo_workflow_content
        )
        console.print(
            f"  [green]‚úì[/green] .forgejo/workflows/projects/{project}/deploy-{app_name}.yml"
        )

    console.print("\n[green]‚úÖ Generation complete![/green]")
    console.print("\n[bold]üìù Next steps:[/bold]")
    console.print("\n1. Review generated files")
    console.print("\n2. Commit app deployment files:")
    console.print("   [dim]cd <app-repo>[/dim]")
    console.print("   [dim]git add .env.superdeploy .github/[/dim]")
    console.print('   [dim]git commit -m "Add SuperDeploy config"[/dim]')
    console.print("\n3. Deploy infrastructure:")
    console.print(f"   [red]superdeploy up -p {project}[/red]")


def _build_github_secrets_documentation(passwords, config):
    """
    Build documentation for GitHub secrets that need to be set.

    Args:
        passwords: Dictionary of generated passwords by addon
        config: Project configuration dictionary

    Returns:
        Dictionary with instructions for setting GitHub secrets
    """
    project_name = config["project"]["name"]
    github_org = config.get("github", {}).get("organization", f"{project_name}io")
    apps = config.get("apps", {})

    docs = {
        "instructions": "Use GitHub CLI to set these secrets for each app repository",
        "example_commands": [],
        "secrets_by_addon": {},
    }

    # Generate example commands for first app
    if apps:
        first_app = list(apps.keys())[0]
        docs["example_commands"].append(f"# Example for {first_app} repository:")

        for addon_name, addon_passwords in passwords.items():
            for var_name, var_info in addon_passwords.items():
                value = var_info["value"]
                description = var_info.get("description", "")

                docs["example_commands"].append(
                    f'gh secret set {var_name} -b "{value}" -R {github_org}/{first_app}  # {description}'
                )

        docs["example_commands"].append("")
        docs["example_commands"].append("# Repeat for other app repositories:")
        for app_name in list(apps.keys())[1:]:
            docs["example_commands"].append(f"# - {github_org}/{app_name}")

    # Document secrets by addon
    for addon_name, addon_passwords in passwords.items():
        docs["secrets_by_addon"][addon_name] = {
            "secrets": list(addon_passwords.keys()),
            "values": {
                var_name: {
                    "value": var_info["value"],
                    "description": var_info.get("description", ""),
                }
                for var_name, var_info in addon_passwords.items()
            },
        }

    return docs


def generate_passwords(addons):
    """
    Generate passwords for addons that require them.

    Only generates passwords for environment variables that have both:
    - secret: true
    - generate: true

    Args:
        addons: Dictionary of loaded addons

    Returns:
        Dictionary with addon context and generated passwords
        Format: {
            'addon_name': {
                'VAR_NAME': 'generated_password',
                ...
            }
        }
    """
    passwords = {}

    for addon_name, addon in addons.items():
        addon_passwords = {}

        # Check env_vars in metadata for password fields
        env_vars = addon.metadata.get("env_vars", [])

        for env_var in env_vars:
            if isinstance(env_var, dict):
                # Check if this is a secret that should be generated
                if env_var.get("secret") and env_var.get("generate"):
                    var_name = env_var.get("name")
                    description = env_var.get("description", "")

                    if var_name:
                        # Generate secure password (32 bytes = 43 characters in base64)
                        addon_passwords[var_name] = {
                            "value": secrets.token_urlsafe(32),
                            "description": description,
                        }

        # Only add addon to passwords if it has any generated passwords
        if addon_passwords:
            passwords[addon_name] = addon_passwords

    return passwords


def generate_docker_compose_apps(config, compose_dir):
    """
    Generate docker-compose.apps.yml for application services.

    Args:
        config: Project configuration dictionary
        compose_dir: Directory to write compose file to
    """
    project_name = config["project"]["name"]
    apps = config.get("apps", {})

    lines = [
        f"# App Services for {project_name}",
        "# Auto-generated by: superdeploy generate",
        "",
        "networks:",
        f"  {project_name}-network:",
        f"    name: {project_name}-network",
        "    external: true",
        "",
        "services:",
    ]

    for app_name, app_config in apps.items():
        # Support both simple port and external_port/internal_port
        external_port = app_config.get("external_port")
        internal_port = app_config.get("internal_port")

        # Fallback to simple port if external/internal not specified
        if external_port is None or internal_port is None:
            port = app_config.get("port", 8000)
            external_port = port
            internal_port = port

        tag_var = f"{app_name.upper()}_TAG"  # e.g., API_TAG

        # Resource limits with sensible defaults
        resources = app_config.get("resources", {})
        memory_limit = resources.get("memory", "512M")
        cpu_limit = resources.get("cpu", "1.0")
        memory_reservation = resources.get("memory_reservation", "256M")
        cpu_reservation = resources.get("cpu_reservation", "0.5")

        lines.extend(
            [
                "",
                f"  {app_name}:",
                f"    image: ${{DOCKER_REGISTRY:-docker.io}}/${{DOCKER_ORG}}/{app_name}:"
                + "${"
                + tag_var
                + "}",
                f"    container_name: {project_name}-{app_name}",
                "    restart: unless-stopped",
                "    ports:",
                f'      - "{external_port}:{internal_port}"',
                "    env_file:",
                f"      - .env.{app_name}",
                "    networks:",
                f"      - {project_name}-network",
                "    # RESOURCE LIMITS: Prevent OOM and ensure fair resource sharing",
                "    deploy:",
                "      resources:",
                "        limits:",
                f"          memory: {memory_limit}",
                f"          cpus: '{cpu_limit}'",
                "        reservations:",
                f"          memory: {memory_reservation}",
                f"          cpus: '{cpu_reservation}'",
            ]
        )

    (compose_dir / "docker-compose.apps.yml").write_text("\n".join(lines))


def generate_workflow(config, app_name, addons, template_merger):
    """
    Generate GitHub Actions workflow using addon system.
    """
    project_name = config["project"]["name"]
    # Docker org comes from .env, but we need it for workflow generation
    # Load from environment variables that were already loaded
    from cli.utils import load_env

    env = load_env(project_name)
    docker_org = env.get("DOCKER_ORG", project_name)

    # Build env section from addons (each line should already look like: "  FOO: ${{ secrets.FOO }}")
    env_vars = template_merger.merge_workflow_env(addons)
    env_section = "\n".join(env_vars)

    # ONLY interpolate docker_org/app_name here. Keep GA expressions escaped with quadruple braces.
    workflow = """name: Build and Deploy

on:
  push:
    branches:
      - production
  workflow_dispatch:

env:
  REGISTRY: docker.io
  IMAGE_NAME: {docker_org}/{app_name}

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{{{ secrets.DOCKER_USERNAME }}}}
          password: ${{{{ secrets.DOCKER_TOKEN }}}}
      
      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{{{ env.REGISTRY }}}}/${{{{ env.IMAGE_NAME }}}}:${{{{ github.sha }}}}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Prepare environment bundle
        id: env_bundle""".format(docker_org=docker_org, app_name=app_name)

    if env_section:
        # DO NOT format this block; just append so inner ${ { ‚Ä¶ } } stays intact.
        workflow += "\n        env:\n" + env_section + "\n"

    workflow += r"""
        run: |
          # Merge .env files using shell
          cp .env /tmp/app.env 2>/dev/null || touch /tmp/app.env
          
          if [ -f .env.superdeploy ]; then
            while IFS='=' read -r key value || [ -n "$key" ]; do
              # Skip empty lines and comments
              [ -z "$key" ] && continue
              [[ "$key" =~ ^[[:space:]]*# ]] && continue
              
              # Expand ${VAR} syntax
              if [[ "$value" =~ ^\$\{([^}]+)\}$ ]]; then
                var_name="${BASH_REMATCH[1]}"
                value="${!var_name}"
              fi
              
              # Update or append to merged env
              if grep -q "^${key}=" /tmp/app.env 2>/dev/null; then
                sed -i.bak "s|^${key}=.*|${key}=${value}|" /tmp/app.env && rm -f /tmp/app.env.bak
              else
                echo "${key}=${value}" >> /tmp/app.env
              fi
            done < .env.superdeploy
          fi
          
          # Install age for encryption
          curl -sL https://github.com/FiloSottile/age/releases/download/v1.1.1/age-v1.1.1-linux-amd64.tar.gz | tar xz
          sudo mv age/age /usr/local/bin/
          rm -rf age
          
          # Encrypt with AGE and encode with base64
          cat /tmp/app.env | age -r "${{ secrets.AGE_PUBLIC_KEY }}" | base64 -w 0 > /tmp/encrypted.txt
          echo "encrypted=$(cat /tmp/encrypted.txt)" >> "$GITHUB_OUTPUT"
          rm -f /tmp/app.env /tmp/encrypted.txt
      
      - name: Connectivity check to Forgejo
        env:
          FORGEJO_BASE_URL: ${{ secrets.FORGEJO_BASE_URL }}
        run: |
          set -euo pipefail
          echo "Checking reachability of $FORGEJO_BASE_URL ..."
          # Try to reach Forgejo (5 second timeout)
          if curl -sS -I --max-time 5 --connect-timeout 5 "$FORGEJO_BASE_URL" 2>/dev/null; then
            echo "‚úì Forgejo reachable"
          else
            echo "::warning::Forgejo base URL not reachable from GitHub runner."
            echo "This is expected if Forgejo is behind firewall/VPN."
            echo "Deployment will continue but may fail if Forgejo API is not accessible."
            echo "Tip: Check firewall rules, use public IP with port 443, or use self-hosted runner."
          fi
      
      - name: Trigger Forgejo deployment
        env:
          FORGEJO_PAT: ${{ secrets.FORGEJO_PAT }}
          FORGEJO_BASE_URL: ${{ secrets.FORGEJO_BASE_URL }}
          FORGEJO_ORG: ${{ secrets.FORGEJO_ORG }}
        run: |
          set -euo pipefail
          
          # Debug: Show PAT prefix (first 10 chars only)
          echo "PAT prefix: ${FORGEJO_PAT:0:10}..."
          echo "Base URL: $FORGEJO_BASE_URL"
          echo "Org: $FORGEJO_ORG"
          
          # Test PAT first
          echo "Testing PAT..."
          TEST_RESPONSE=$(curl -sS -i -H "Authorization: token $FORGEJO_PAT" "$FORGEJO_BASE_URL/api/v1/user")
          TEST_CODE=$(echo "$TEST_RESPONSE" | head -n1 | cut -d' ' -f2)
          echo "PAT test result: HTTP $TEST_CODE"
          
          if [[ "$TEST_CODE" != "200" ]]; then
            echo "::error::PAT is invalid (HTTP $TEST_CODE)"
            echo "$TEST_RESPONSE" | tail -5
            exit 1
          fi
          
          # Build JSON payload and trigger deployment
          RESPONSE=$(curl -sS -i -X POST \
            --max-time 30 \
            --connect-timeout 10 \
            -H "Authorization: token $FORGEJO_PAT" \
            -H "Content-Type: application/json" \
            -d "{\"ref\":\"master\",\"inputs\":{\"image\":\"${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\",\"env_bundle\":\"${{ steps.env_bundle.outputs.encrypted }}\",\"git_sha\":\"${{ github.sha }}\"}}" \
            "$FORGEJO_BASE_URL/api/v1/repos/$FORGEJO_ORG/superdeploy/actions/workflows/projects%2F%(project_name)s%2Fdeploy-%(app_name)s.yml/dispatches")
          
          HTTP_CODE=$(echo "$RESPONSE" | head -n1 | cut -d' ' -f2)
          BODY=$(echo "$RESPONSE" | tail -n1)
          
          echo "Response: $BODY"
          echo "HTTP Status: $HTTP_CODE"
          
          if [[ "$HTTP_CODE" =~ ^2[0-9][0-9]$ ]]; then
            echo "‚úì Deployment triggered successfully"
          else
            echo "::error::Failed to trigger Forgejo deployment (HTTP $HTTP_CODE)"
            echo "::error::Response: $BODY"
            exit 1
          fi
"""

    # Safely inject project/app into the JSON literal placeholders (not GA syntax)
    workflow = workflow.replace("%(project_name)s", project_name).replace(
        "%(app_name)s", app_name
    )
    return workflow


def generate_forgejo_workflow(config, app_name):
    """
    Generate Forgejo workflow for a specific app in the project.
    This workflow runs on the Forgejo instance and deploys to the correct VM.
    All steps are explicit (no composite actions or reusable workflows).
    """
    project_name = config["project"]["name"]
    app_config = config["apps"][app_name]
    # Get VM role from app config (e.g., "web", "api", "worker")
    vm_role = app_config.get("vm", "core")
    # Get port from app config
    port = app_config.get("port", 8080)

    workflow = f"""name: Deploy {project_name.title()} {app_name.title()}

on:
  workflow_dispatch:
    inputs:
      image:
        description: 'Docker image with tag'
        required: true
        type: string
      env_bundle:
        description: 'AGE-encrypted environment variables bundle (base64 encoded)'
        required: true
        type: string
      git_sha:
        description: 'Git commit SHA'
        required: true
        type: string
      git_ref:
        description: 'Git ref (branch/tag)'
        required: false
        default: 'production'
        type: string

jobs:
  deploy:
    runs-on: [self-hosted, {project_name}, {vm_role}]
    
    steps:
      - name: Check age installation
        run: |
          if command -v age &> /dev/null; then
            echo "‚úÖ age already installed ($(age --version))"
          else
            echo "üì• Installing age..."
            curl -sL https://github.com/FiloSottile/age/releases/download/v1.1.1/age-v1.1.1-linux-amd64.tar.gz | tar xz
            sudo mv age/age /usr/local/bin/
            rm -rf age
            echo "‚úÖ age installed ($(age --version))"
          fi
      
      - name: Decode env bundle
        run: |
          echo "üì¶ Decoding environment bundle..."
          echo "${{{{ inputs.env_bundle }}}}" | base64 -d > /tmp/encrypted.age
          SIZE=$(wc -c < /tmp/encrypted.age)
          echo "‚úÖ Decoded: $SIZE bytes"
      
      - name: Decrypt with AGE
        env:
          AGE_SECRET_KEY: ${{{{ secrets.AGE_SECRET_KEY }}}}
        run: |
          echo "üîê Decrypting with AGE..."
          
          if [ -z "$AGE_SECRET_KEY" ]; then
            echo "‚ùå AGE_SECRET_KEY not set!"
            exit 1
          fi
          
          printf '%s' "$AGE_SECRET_KEY" > /tmp/age-key.txt
          chmod 600 /tmp/age-key.txt
          
          if ! age -d -i /tmp/age-key.txt /tmp/encrypted.age > /tmp/decrypted.env 2>&1; then
            echo "‚ùå Decryption failed!"
            cat /tmp/decrypted.env || true
            rm -f /tmp/age-key.txt /tmp/encrypted.age /tmp/decrypted.env
            exit 1
          fi
          
          rm -f /tmp/age-key.txt /tmp/encrypted.age
          
          if [ ! -s /tmp/decrypted.env ]; then
            echo "‚ùå Decrypted file is empty!"
            exit 1
          fi
          
          SIZE=$(wc -c < /tmp/decrypted.env)
          echo "‚úÖ Decrypted: $SIZE bytes"
      
      - name: Login to Docker Hub
        env:
          DOCKER_USERNAME: ${{{{ secrets.DOCKER_USERNAME }}}}
          DOCKER_TOKEN: ${{{{ secrets.DOCKER_TOKEN }}}}
        run: |
          echo "üîë Logging in to Docker Hub..."
          echo "$DOCKER_TOKEN" | docker login -u "$DOCKER_USERNAME" --password-stdin
          echo "‚úÖ Logged in"
      
      - name: Pull Docker image
        run: |
          echo "üì• Pulling: ${{{{ inputs.image }}}}"
          docker pull ${{{{ inputs.image }}}}
          echo "‚úÖ Image pulled"
      
      - name: Generate Docker Compose file
        run: |
          echo "üìù Generating docker-compose.yml..."
          
          PROJECT="{project_name}"
          SERVICE="{app_name}"
          IMAGE="${{{{ inputs.image }}}}"
          PORT="{port}"
          GIT_SHA="${{{{ inputs.git_sha }}}}"
          
          sudo mkdir -p /opt/apps/$PROJECT/compose
          
          cat > /tmp/docker-compose-$SERVICE.yml << 'DOCKERCOMPOSEEOF'
          services:
            SERVICE_PLACEHOLDER:
              image: IMAGE_PLACEHOLDER
              container_name: CONTAINER_PLACEHOLDER
              restart: unless-stopped
              env_file:
                - /tmp/decrypted.env
              networks:
                - NETWORK_PLACEHOLDER
              ports:
                - "PORT_PLACEHOLDER:PORT_PLACEHOLDER"
              labels:
                - "project=PROJECT_PLACEHOLDER"
                - "service=SERVICE_PLACEHOLDER"
                - "git.sha=GIT_SHA_PLACEHOLDER"
          
          networks:
            NETWORK_PLACEHOLDER:
              name: NETWORK_PLACEHOLDER
              external: true
          DOCKERCOMPOSEEOF
          
          # Replace placeholders
          sed -i "s/SERVICE_PLACEHOLDER/$SERVICE/g" /tmp/docker-compose-$SERVICE.yml
          sed -i "s/PROJECT_PLACEHOLDER/$PROJECT/g" /tmp/docker-compose-$SERVICE.yml
          sed -i "s|IMAGE_PLACEHOLDER|$IMAGE|g" /tmp/docker-compose-$SERVICE.yml
          sed -i "s/CONTAINER_PLACEHOLDER/$PROJECT-$SERVICE/g" /tmp/docker-compose-$SERVICE.yml
          sed -i "s/NETWORK_PLACEHOLDER/$PROJECT-network/g" /tmp/docker-compose-$SERVICE.yml
          sed -i "s/PORT_PLACEHOLDER/$PORT/g" /tmp/docker-compose-$SERVICE.yml
          sed -i "s/GIT_SHA_PLACEHOLDER/$GIT_SHA/g" /tmp/docker-compose-$SERVICE.yml
          
          sudo mv /tmp/docker-compose-$SERVICE.yml /opt/apps/$PROJECT/compose/
          echo "‚úÖ Compose file created"
      
      - name: Deploy with zero-downtime
        run: |
          echo "üöÄ Deploying {app_name} - zero-downtime..."
          
          cd /opt/apps/{project_name}/compose
          
          CONTAINER_NAME="{project_name}-{app_name}"
          NEW_CONTAINER="${{CONTAINER_NAME}}-new-$$"
          TEMP_PORT=$(expr {port} + 10000)  # Temporary port for new container
          
          # Clean up any old temp containers first
          echo "üßπ Cleaning up old temp containers..."
          docker ps -a --filter name=${{CONTAINER_NAME}}-new- -q | xargs -r docker rm -f 2>/dev/null || true
          
          # Create temporary compose file with new container name and temp port
          cp docker-compose-{app_name}.yml /tmp/docker-compose-new-{app_name}.yml
          sed -i "s/container_name: $CONTAINER_NAME/container_name: $NEW_CONTAINER/" /tmp/docker-compose-new-{app_name}.yml
          sed -i "s/- {port}:{port}/- $TEMP_PORT:{port}/" /tmp/docker-compose-new-{app_name}.yml
          
          # Debug: show what was changed
          echo "üìù Checking port mapping..."
          grep "ports:" -A 1 /tmp/docker-compose-new-{app_name}.yml
          
          echo "üê≥ Starting new container: $NEW_CONTAINER on temp port $TEMP_PORT"
          docker compose -f /tmp/docker-compose-new-{app_name}.yml up -d
          
          # Wait for container to start
          echo "‚è≥ Waiting for container to be ready..."
          sleep 5
          
          # Check if new container is running
          if [ -n "$(docker ps -q --filter name=$NEW_CONTAINER)" ]; then
            echo "‚úÖ New container is running"
            
            # Wait for container to be ready
            echo "‚è≥ Waiting 10 seconds for container to start..."
            sleep 10
            
            # Check if still running
            if [ -n "$(docker ps -q --filter name=$NEW_CONTAINER)" ]; then
              echo "‚úÖ Container is healthy and running"
            else
              echo "‚ùå Container stopped unexpectedly"
              docker logs $NEW_CONTAINER 2>&1 | tail -20
              exit 1
            fi
            
            # Stop and remove old container
            echo "‚è∏Ô∏è  Stopping old container..."
            docker stop $CONTAINER_NAME 2>/dev/null || true
            docker rm $CONTAINER_NAME 2>/dev/null || true
            
            # Stop temp container (it's on temp port)
            echo "üîÑ Recreating container on correct port..."
            docker stop $NEW_CONTAINER 2>/dev/null || true
            docker rm $NEW_CONTAINER 2>/dev/null || true
            
            # Start with original compose (correct port and name)
            docker compose -f docker-compose-{app_name}.yml up -d
            
            echo "‚úÖ Zero-downtime deployment complete!"
          else
            echo "‚ùå New container failed to start"
            docker stop $NEW_CONTAINER 2>/dev/null || true
            docker rm $NEW_CONTAINER 2>/dev/null || true
            exit 1
          fi
          
          # Cleanup temp file
          rm -f /tmp/docker-compose-new-{app_name}.yml
      
      - name: Show container status
        run: |
          echo "üìä Container status:"
          docker ps --filter name={project_name}-{app_name}
      
      - name: Cleanup
        if: always()
        run: |
          rm -f /tmp/decrypted.env /tmp/encrypted.age /tmp/age-key.txt
          echo "üßπ Cleanup complete"
"""
    return workflow


if __name__ == "__main__":
    generate()
