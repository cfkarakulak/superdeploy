"""
Project initialization command with interactive setup
"""

import os
import yaml
import click
import ipaddress
from pathlib import Path
from datetime import datetime
from rich.console import Console
from rich.prompt import Prompt, Confirm
from rich.table import Table
from jinja2 import Template
import secrets

console = Console()


def get_available_addons():
    """Get list of available addons from the addons directory"""
    from cli.utils import get_project_root
    
    project_root = get_project_root()
    addons_dir = project_root / "addons"
    
    available = []
    
    if addons_dir.exists():
        for addon_dir in addons_dir.iterdir():
            if addon_dir.is_dir() and not addon_dir.name.startswith('.'):
                # Check if addon.yml exists
                addon_yml = addon_dir / "addon.yml"
                if addon_yml.exists():
                    try:
                        with open(addon_yml) as f:
                            addon_meta = yaml.safe_load(f)
                            if addon_meta and 'name' in addon_meta:
                                available.append({
                                    'name': addon_meta['name'],
                                    'description': addon_meta.get('description', ''),
                                    'version': addon_meta.get('version', 'latest'),
                                    'category': addon_meta.get('category', 'other')
                                })
                    except (yaml.YAMLError, IOError):
                        # Skip invalid addons
                        continue
    
    return available


def get_used_subnets():
    """Get list of subnets already in use by other projects"""
    used_subnets = []

    # Use local projects directory
    from cli.utils import get_project_root

    project_root = get_project_root()
    projects_dir = project_root / "projects"

    if projects_dir.exists():
        for project_dir in projects_dir.iterdir():
            if project_dir.is_dir():
                config_file = project_dir / "config.yml"
                if config_file.exists():
                    with open(config_file) as f:
                        config = yaml.safe_load(f)
                        if (
                            config
                            and "network" in config
                            and "subnet" in config["network"]
                        ):
                            used_subnets.append(config["network"]["subnet"])

    return used_subnets


def find_next_subnet(used_subnets):
    """Find next available subnet starting from 172.20.0.0/24"""
    base = ipaddress.IPv4Network("172.20.0.0/24")

    # Try subnets incrementally
    for i in range(20, 255):  # 172.20.0.0 to 172.254.0.0
        candidate = ipaddress.IPv4Network(f"172.{i}.0.0/24")
        if str(candidate) not in used_subnets:
            return str(candidate)

    raise ValueError("No available subnets in 172.x.0.0/24 range")


def render_template(template_path, context):
    """Render a template file with given context"""
    with open(template_path) as f:
        template = Template(f.read())

    # Render template with context
    return template.render(**context)


def generate_env_superdeploy(project, service, core_services):
    """Generate .env.superdeploy for a service"""
    lines = [
        "# =============================================================================",
        "# SuperDeploy - Production Environment Overrides",
        "# =============================================================================",
        "# Auto-generated by: superdeploy init",
        "#",
        "# These values OVERRIDE your local .env in production deployment",
        "# Merged by GitHub Actions workflow (.env + .env.superdeploy)",
        "#",
        "# DO NOT EDIT MANUALLY - Regenerate with: superdeploy init",
        "# =============================================================================",
        "",
    ]
    
    # Add core service env vars
    if "postgres" in core_services:
        lines.extend([
            "",
            "# PostgreSQL",
            "POSTGRES_HOST=${POSTGRES_HOST}",
            "POSTGRES_PORT=${POSTGRES_PORT}",
            "POSTGRES_USER=${POSTGRES_USER}",
            "POSTGRES_PASSWORD=${POSTGRES_PASSWORD}",
            "POSTGRES_DB=${POSTGRES_DB}",
        ])
    
    if "rabbitmq" in core_services:
        lines.extend([
            "",
            "# RabbitMQ",
            "RABBITMQ_HOST=${RABBITMQ_HOST}",
            "RABBITMQ_PORT=${RABBITMQ_PORT}",
            "RABBITMQ_USER=${RABBITMQ_USER}",
            "RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}",
        ])
    
    if "redis" in core_services:
        lines.extend([
            "",
            "# Redis",
            "REDIS_HOST=${REDIS_HOST}",
            "REDIS_PORT=${REDIS_PORT}",
            "REDIS_PASSWORD=${REDIS_PASSWORD}",
        ])
    
    if "mongodb" in core_services:
        lines.extend([
            "",
            "# MongoDB",
            "MONGODB_HOST=${MONGODB_HOST}",
            "MONGODB_PORT=${MONGODB_PORT}",
            "MONGODB_USER=${MONGODB_USER}",
            "MONGODB_PASSWORD=${MONGODB_PASSWORD}",
        ])
    
    return "\n".join(lines)


def generate_workflow(project, service, core_services, github_org):
    """Generate GitHub Actions workflow for a service"""
    
    # Build env section
    env_vars = []
    
    if "postgres" in core_services:
        env_vars.extend([
            "    POSTGRES_HOST: ${{ secrets.POSTGRES_HOST }}",
            "    POSTGRES_PORT: ${{ secrets.POSTGRES_PORT }}",
            "    POSTGRES_USER: ${{ secrets.POSTGRES_USER }}",
            "    POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}",
            "    POSTGRES_DB: ${{ secrets.POSTGRES_DB }}",
        ])
    
    if "rabbitmq" in core_services:
        env_vars.extend([
            "    RABBITMQ_HOST: ${{ secrets.RABBITMQ_HOST }}",
            "    RABBITMQ_PORT: ${{ secrets.RABBITMQ_PORT }}",
            "    RABBITMQ_USER: ${{ secrets.RABBITMQ_USER }}",
            "    RABBITMQ_PASSWORD: ${{ secrets.RABBITMQ_PASSWORD }}",
        ])
    
    if "redis" in core_services:
        env_vars.extend([
            "    REDIS_HOST: ${{ secrets.REDIS_HOST }}",
            "    REDIS_PORT: ${{ secrets.REDIS_PORT }}",
            "    REDIS_PASSWORD: ${{ secrets.REDIS_PASSWORD }}",
        ])
    
    if "mongodb" in core_services:
        env_vars.extend([
            "    MONGODB_HOST: ${{ secrets.MONGODB_HOST }}",
            "    MONGODB_PORT: ${{ secrets.MONGODB_PORT }}",
            "    MONGODB_USER: ${{ secrets.MONGODB_USER }}",
            "    MONGODB_PASSWORD: ${{ secrets.MONGODB_PASSWORD }}",
        ])
    
    env_section = "\n".join(env_vars)
    
    workflow = f"""name: Build and Deploy

on:
  push:
    branches:
      - production
  workflow_dispatch:

env:
  REGISTRY: docker.io
  IMAGE_NAME: {github_org}/{service}

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{{{ secrets.DOCKER_USERNAME }}}}
          password: ${{{{ secrets.DOCKER_TOKEN }}}}
      
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{{{ env.REGISTRY }}}}/${{{{ env.IMAGE_NAME }}}}
          tags: |
            type=sha,prefix={{{{branch}}}}-
            type=ref,event=branch
            type=raw,value=latest,enable={{{{is_default_branch}}}}
      
      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{{{ steps.meta.outputs.tags }}}}
          labels: ${{{{ steps.meta.outputs.labels }}}}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Get image digest
        id: digest
        run: |
          DIGEST="${{{{ steps.build.outputs.digest }}}}"
          IMAGE_WITH_DIGEST="${{{{ env.REGISTRY }}}}/${{{{ env.IMAGE_NAME }}}}@${{DIGEST}}"
          echo "image=${{IMAGE_WITH_DIGEST}}" >> $GITHUB_OUTPUT
          echo "short_sha=${{{{GITHUB_SHA:0:7}}}}" >> $GITHUB_OUTPUT
      
      - name: Cache age binary
        id: cache-age
        uses: actions/cache@v3
        with:
          path: /usr/local/bin/age
          key: age-v1.1.1-linux-amd64
      
      - name: Install age
        if: steps.cache-age.outputs.cache-hit != 'true'
        run: |
          curl -sL https://github.com/FiloSottile/age/releases/download/v1.1.1/age-v1.1.1-linux-amd64.tar.gz | tar xz
          sudo mv age/age age/age-keygen /usr/local/bin/
          age --version
      
      - name: Prepare environment bundle
        id: env_bundle
        env:
          # =============================================================================
          # CORE SERVICES (Auto-generated by superdeploy init)
          # =============================================================================
{env_section}
          
          # =============================================================================
          # APP-SPECIFIC SECRETS (Add your own below)
          # =============================================================================
          # Example:
          # {service.upper()}_SECRET_KEY: ${{{{ secrets.{service.upper()}_SECRET_KEY }}}}
          # STRIPE_API_KEY: ${{{{ secrets.STRIPE_API_KEY }}}}
        run: |
          # Merge .env + .env.superdeploy (superdeploy overrides)
          python3 <<'PYEOF'
import os
from pathlib import Path

# Read app's .env (local development values)
env_vars = {{}}
if Path('.env').exists():
    with open('.env') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                env_vars[key] = value

# Override with .env.superdeploy (production values)
if Path('.env.superdeploy').exists():
    with open('.env.superdeploy') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                # Substitute ${{VAR}} with env value
                if value.startswith('${{') and value.endswith('}}'):
                    var_name = value[2:-1]
                    value = os.environ.get(var_name, '')
                env_vars[key] = value
else:
    print("âš ï¸  .env.superdeploy not found, using only .env")

# Write merged
with open('/tmp/app.env', 'w') as f:
    for key, value in env_vars.items():
        f.write(f'{{key}}={{value}}\\n')

print(f"âœ“ Merged {{len(env_vars)}} environment variables")
PYEOF
          
          # Encrypt with AGE
          cat /tmp/app.env | age -r "${{{{ secrets.AGE_PUBLIC_KEY }}}}" | base64 -w 0 > /tmp/encrypted.txt
          
          # Output as single line
          ENCRYPTED=$(cat /tmp/encrypted.txt)
          echo "encrypted=${{ENCRYPTED}}" >> $GITHUB_OUTPUT
          
          # Cleanup
          rm -f /tmp/app.env /tmp/encrypted.txt
      
      - name: Trigger Forgejo deployment
        env:
          FORGEJO_URL: ${{{{ secrets.FORGEJO_BASE_URL }}}}
          FORGEJO_PAT: ${{{{ secrets.FORGEJO_PAT }}}}
        run: |
          # Extract service from repo name
          REPO_NAME="${{{{ github.repository }}}}"
          SERVICE="${{REPO_NAME##*/}}"
          
          # Get project and Forgejo config from secrets
          PROJECT="${{{{ secrets.PROJECT_NAME }}}}"
          FORGEJO_ORG="${{{{ secrets.FORGEJO_ORG }}}}"
          FORGEJO_REPO="${{{{ secrets.FORGEJO_REPO }}}}"
          
          # Build JSON payload
          PAYLOAD=$(cat <<EOF
          {{
            "ref": "master",
            "inputs": {{
              "project": "${{PROJECT}}",
              "service": "${{SERVICE}}",
              "image": "${{{{ steps.digest.outputs.image }}}}",
              "env_bundle": "${{{{ steps.env_bundle.outputs.encrypted }}}}",
              "git_sha": "${{{{ github.sha }}}}",
              "git_ref": "${{{{ github.ref_name }}}}"
            }}
          }}
          EOF
          )
          
          echo "ðŸ“¦ Payload preview:"
          echo "${{PAYLOAD}}" | jq -r '.inputs | "project=\\(.project), service=\\(.service)"'
          
          curl -X POST \\
            -H "Authorization: token ${{FORGEJO_PAT}}" \\
            -H "Content-Type: application/json" \\
            -d "${{PAYLOAD}}" \\
            "${{FORGEJO_URL}}/api/v1/repos/${{FORGEJO_ORG}}/${{FORGEJO_REPO}}/actions/workflows/deploy.yml/dispatches"
          
          echo "âœ… Deployment triggered!"
          echo "ðŸŒ Check status: ${{FORGEJO_URL}}/${{FORGEJO_ORG}}/${{FORGEJO_REPO}}/actions"
"""
    
    return workflow


@click.command()
@click.option("--project", "-p", required=True, help="Project name")
@click.option("--app", multiple=True, help="App in format name:path (e.g., api:../app-repos/api)")
@click.option("--subnet", help="Network subnet (e.g., 172.20.0.0/24)")
@click.option("--github-org", help="GitHub organization name")
@click.option("--no-interactive", is_flag=True, help="Non-interactive mode with defaults")
@click.option("--yes", "-y", is_flag=True, help="Skip confirmations")
def init(project, app, subnet, github_org, no_interactive, yes):
    """
    Initialize a new project (creates config template)

    Example:
        superdeploy init -p cheapa
        # Edit: projects/cheapa/project.yml
        superdeploy generate -p cheapa
    """
    console.print(f"\n[bold cyan]ðŸŽ¯ Initializing project: {project}[/bold cyan]")
    console.print("â”" * 40)

    from cli.utils import get_project_root

    project_root = get_project_root()
    projects_dir = project_root / "projects"
    project_dir = projects_dir / project

    # Check if project already exists
    if project_dir.exists():
        console.print(f"[red]âŒ Project '{project}' already exists![/red]")
        console.print(f"[dim]Edit: {project_dir}/project.yml[/dim]")
        console.print(f"[dim]Then run: superdeploy generate -p {project}[/dim]")
        return
    
    # Create project directory
    project_dir.mkdir(parents=True, exist_ok=True)

    # Determine mode
    interactive = not no_interactive

    # App selection with paths
    apps = {}  # {name: path}

    if app:
        # User provided apps via CLI
        for app_spec in app:
            if ":" not in app_spec:
                console.print(f"[red]âŒ Invalid format: {app_spec}[/red]")
                console.print("[dim]Use: --app name:path (e.g., --app api:../app-repos/api)[/dim]")
                raise SystemExit(1)
            
            name, path = app_spec.split(":", 1)
            name = name.strip().lower()
            app_path = Path(path).expanduser().resolve()
            
            if not app_path.exists():
                console.print(f"[red]âŒ Path not found: {app_path}[/red]")
                raise SystemExit(1)
            
            apps[name] = app_path
    elif interactive:
        # Interactive app selection with paths
        console.print("\n[bold]Application services:[/bold]")
        console.print("  [dim]Add your app repos (name + path to repo)[/dim]")
        console.print("  [dim]Example: api â†’ ../app-repos/api[/dim]")
        console.print("  [dim]Press ENTER with empty name to finish[/dim]\n")
        
        service_num = 1
        
        while True:
            service_name = Prompt.ask(
                f"  Service {service_num} name",
                default="" if service_num > 2 else ("api" if service_num == 1 else "dashboard")
            )
            
            if not service_name or service_name.strip() == "":
                if service_num == 1:
                    console.print("[yellow]âš ï¸  At least one service required[/yellow]")
                    continue
                break
            
            service_name = service_name.strip().lower()
            
            # Validate service name
            if not service_name.replace("-", "").replace("_", "").isalnum():
                console.print("[yellow]âš ï¸  Invalid name (use letters, numbers, - or _)[/yellow]")
                continue
            
            if service_name in apps:
                console.print(f"[yellow]âš ï¸  '{service_name}' already added[/yellow]")
                continue
            
            # Ask for path
            default_path = f"../app-repos/{service_name}"
            service_path = Prompt.ask(f"  Service {service_num} path", default=default_path)
            app_path = Path(service_path).expanduser().resolve()
            
            if not app_path.exists():
                console.print(f"[yellow]âš ï¸  Path not found: {app_path}[/yellow]")
                create = Confirm.ask("  Create directory?", default=False)
                if create:
                    app_path.mkdir(parents=True, exist_ok=True)
                    console.print(f"  [green]âœ“[/green] Created: {app_path}")
                else:
                    continue
            
            apps[service_name] = app_path
            console.print(f"  [green]âœ“[/green] Added: {service_name} â†’ {app_path}")
            service_num += 1
        
        console.print(f"\n  [cyan]Total services: {', '.join(apps.keys())}[/cyan]")
    else:
        # Default for non-interactive
        console.print("[red]âŒ No apps specified![/red]")
        console.print("[dim]Use --app flag or run without --no-interactive[/dim]")
        raise SystemExit(1)
    
    selected_services = list(apps.keys())

    # Network configuration
    used_subnets = get_used_subnets()

    if subnet:
        project_subnet = subnet
    elif interactive:
        console.print("\n[bold]Configure networking:[/bold]")
        auto_subnet = Confirm.ask("  Auto-assign subnet?", default=True)

        if auto_subnet:
            project_subnet = find_next_subnet(used_subnets)
            console.print(f"\n[green]âœ¨ Auto-assigned subnet: {project_subnet}[/green]")
        else:
            project_subnet = Prompt.ask(
                "  Enter custom subnet", default="172.20.0.0/24"
            )
    else:
        project_subnet = find_next_subnet(used_subnets)

    # Core services selection (addon-based)
    available_addons = get_available_addons()
    
    # Filter to only show database, cache, queue, and proxy addons (not monitoring)
    available_core_services = [
        (addon['name'], f"{addon['description']} ({addon['version']})")
        for addon in available_addons
        if addon['category'] in ['database', 'cache', 'queue', 'proxy']
    ]
    
    # Fallback if no addons found
    if not available_core_services:
        available_core_services = [
            ("postgres", "PostgreSQL 15 - Relational database"),
            ("rabbitmq", "RabbitMQ 3.12 - Message queue"),
            ("redis", "Redis 7 - In-memory cache/store"),
            ("mongodb", "MongoDB 7 - Document database"),
        ]
    
    core_services = ["postgres", "rabbitmq"]  # Default
    
    if interactive:
        import inquirer
        
        console.print("\n[bold]Core services configuration (Addon-based):[/bold]")
        console.print("  [dim]Use SPACE to select, ENTER to confirm[/dim]")
        console.print("  [dim]These services are SHARED by all apps (api, dashboard, etc.)[/dim]")
        console.print(f"  [dim]Available addons: {len(available_addons)} found[/dim]\n")
        
        questions = [
            inquirer.Checkbox(
                'services',
                message="Select core services",
                choices=[f"{name}: {desc}" for name, desc in available_core_services],
                default=[f"{name}: {desc}" for name, desc in available_core_services 
                        if name in ["postgres", "rabbitmq"]],
            ),
        ]
        
        answers = inquirer.prompt(questions)
        if answers and answers['services']:
            # Extract service names from "name: description" format
            core_services = [choice.split(":")[0].strip() for choice in answers['services']]
        else:
            console.print("[yellow]âš ï¸  No services selected, using defaults[/yellow]")
            core_services = ["postgres", "rabbitmq"]
    
    # Database configuration
    generate_passwords = True
    if interactive:
        console.print("\n[bold]Password generation:[/bold]")
        generate_passwords = Confirm.ask("  Generate secure passwords?", default=True)

    # Monitoring
    enable_monitoring = True
    if interactive:
        enable_monitoring = Confirm.ask(
            "\nEnable monitoring for this project?", default=True
        )

    # GitHub Organization
    if not github_org:
        github_org = f"{project}io"  # Default
    if interactive and not github_org:
        console.print("\n[bold]GitHub organization:[/bold]")
        github_org = Prompt.ask("  GitHub org name", default=f"{project}io")

    # Domain
    project_domain = ""
    if interactive:
        console.print("\n[bold]Configure domain (optional):[/bold]")
        project_domain = Prompt.ask(
            f"  Domain for {project}", default=f"{project}.example.com"
        )
        if project_domain == f"{project}.example.com":
            project_domain = ""  # Don't save example domain

    # Dynamic port assignments (no hardcoded service names!)
    base_external_port = 8000 + len(used_subnets) * 100  # Offset by 100 per project
    base_internal_port = 8000

    # Summary
    console.print("\n[bold cyan]ðŸ“‹ Summary:[/bold cyan]")
    console.print("â”" * 40)

    table = Table(show_header=False, box=None)
    table.add_column("Property", style="dim")
    table.add_column("Value", style="bright_white")

    table.add_row("Project:", project)
    table.add_row("Services:", ", ".join(selected_services))
    table.add_row("Network:", project_subnet)
    table.add_row("Database:", "PostgreSQL 15")
    table.add_row("Queue:", "RabbitMQ 3.12")
    table.add_row("Cache:", "Redis 7")
    table.add_row("GitHub Org:", github_org)
    table.add_row("Monitoring:", "âœ“ Enabled" if enable_monitoring else "âœ— Disabled")
    if project_domain:
        table.add_row("Domain:", project_domain)

    console.print(table)

    # Confirm
    if interactive and not yes and not Confirm.ask("\n[bold]Create project?[/bold]", default=True):
        console.print("[yellow]Cancelled.[/yellow]")
        return

    # Build port assignments dynamically (TRULY GENERIC - NO HARDCODED SERVICE NAMES!)
    port_assignments = {}

    for idx, service in enumerate(selected_services):
        # Every service gets dynamically assigned ports
        port_assignments[service] = {
            "external": base_external_port + (idx * 10),  # 8000, 8010, 8020...
            "internal": base_internal_port,  # Always 8000 inside container
        }

    # Build temporary project config for validation
    temp_config = {
        "project": project,
        "infrastructure": {
            "forgejo": {
                "version": "1.21",
                "port": 3001,
                "ssh_port": 2222,
                "admin_user": "admin",
                "admin_email": f"admin@{project}.local",
                "org": github_org,
                "repo": "superdeploy",
                "db_name": "forgejo",
                "db_user": "forgejo"
            }
        },
        "network": {
            "subnet": project_subnet
        },
        "apps": {
            app_name: {
                "path": str(app_path),
                "port": port_assignments[app_name]["external"]
            }
            for app_name, app_path in apps.items()
        },
        "core_services": {
            service: {} for service in core_services
        }
    }

    # Validate configuration before creating files
    console.print("\n[dim]Validating configuration...[/dim]")
    from cli.core.validator import ValidationEngine, ValidationException
    from cli.core.addon_loader import AddonLoader

    validator = ValidationEngine(projects_dir)
    
    # Get available addon names for validation
    available_addon_names = {addon['name'] for addon in available_addons}
    
    # Load addons for validation (if addon system is available)
    try:
        addons_dir = project_root / "addons"
        if addons_dir.exists():
            addon_loader = AddonLoader(addons_dir)
            addons = addon_loader.load_addons_for_project(temp_config)
        else:
            # If addon system not available, use empty dict
            addons = {}
    except Exception as e:
        console.print(f"[yellow]âš  Could not load addons for validation: {e}[/yellow]")
        addons = {}
    
    # Run validation
    try:
        validator.validate_and_raise(temp_config, addons, project, available_addon_names)
        console.print("[dim]âœ“ Validation passed[/dim]")
    except ValidationException as e:
        console.print(f"\n[red]{e}[/red]")
        console.print("\n[yellow]âš  Fix validation errors before proceeding[/yellow]")
        console.print("[dim]Hint: Use different subnet or ports to avoid conflicts[/dim]")
        return

    # Create project structure
    console.print("\n[dim]Creating project structure...[/dim]")
    
    # Create project directory
    project_dir.mkdir(parents=True, exist_ok=True)

    # Template context for project.yml
    context = {
        "PROJECT": project,
        "CREATED_AT": datetime.now().isoformat(),
        "SUBNET": project_subnet,
    }
    
    # Build apps dict for template
    apps_dict = {}
    for idx, (app_name, app_path) in enumerate(apps.items()):
        apps_dict[app_name] = {
            "path": str(app_path),
            "vm": "core",
            "port": port_assignments[app_name]["external"]
        }
    
    # Build core_services dict for template
    addon_versions = {addon['name']: addon['version'] for addon in available_addons}
    core_services_dict = {}
    for service in core_services:
        default_version = addon_versions.get(service, "latest")
        
        if service == "postgres":
            core_services_dict[service] = {
                "version": default_version,
                "user": f"{project}_user",
                "database": f"{project}_db",
            }
        elif service in ["rabbitmq", "mongodb"]:
            core_services_dict[service] = {
                "version": default_version,
                "user": f"{project}_user",
            }
        else:
            core_services_dict[service] = {
                "version": default_version,
            }
    
    # Create project.yml manually (template has placeholders we need to replace)
    project_yml_content = f"""# =============================================================================
# {project} - Project Configuration
# =============================================================================
# Auto-generated by: superdeploy init -p {project}
# Edit this file, then run: superdeploy generate -p {project}
# =============================================================================

project: {project}
description: {project} project
created_at: {datetime.now().isoformat()}

# =============================================================================
# Infrastructure Configuration
# =============================================================================
# Core infrastructure services (always deployed)
infrastructure:
  forgejo:
    version: "1.21"
    port: 3001
    ssh_port: 2222
    admin_user: "admin"
    admin_email: "admin@{project}.local"
    org: "{github_org}"
    repo: "superdeploy"
    db_name: "forgejo"
    db_user: "forgejo"

# =============================================================================
# VMs (Infrastructure)
# =============================================================================
vms:
  core:
    count: 1
    machine_type: e2-medium
    disk_size: 20
    services:
      - postgres
      - rabbitmq
      - forgejo

# =============================================================================
# Core Services (Addon-Based Infrastructure)
# =============================================================================
core_services:
"""
    
    # Add core services
    for service, config in core_services_dict.items():
        project_yml_content += f"  {service}:\n"
        for key, value in config.items():
            project_yml_content += f"    {key}: \"{value}\"\n"
    
    project_yml_content += f"""
# =============================================================================
# Application Services
# =============================================================================
apps:
"""
    
    # Add apps
    for app_name, app_config in apps_dict.items():
        project_yml_content += f"  {app_name}:\n"
        project_yml_content += f"    path: {app_config['path']}\n"
        project_yml_content += f"    vm: {app_config['vm']}\n"
        project_yml_content += f"    port: {app_config['port']}\n"
    
    project_yml_content += f"""
# =============================================================================
# GitHub Configuration
# =============================================================================
github:
  organization: {github_org}

# =============================================================================
# Network Configuration
# =============================================================================
network:
  subnet: {project_subnet}

# =============================================================================
# Monitoring (Optional)
# =============================================================================
monitoring:
  enabled: {str(enable_monitoring).lower()}
  prometheus: true
  grafana: true

# =============================================================================
# Domain (Optional)
# =============================================================================
domain: "{project_domain}"
"""
    
    # Write project.yml
    project_yml_path = project_dir / "project.yml"
    project_yml_path.write_text(project_yml_content)
    console.print(f"  [green]âœ“[/green] Created: {project_yml_path}")
    
    # Success message
    console.print("\n[green]âœ… Project initialized successfully![/green]")

    # Next steps
    console.print("\n[bold]ðŸ“ Next steps:[/bold]")
    console.print(f"\n1. Generate deployment files:")
    console.print(f"   [cyan]superdeploy generate -p {project}[/cyan]")
    console.print(f"\n2. Deploy infrastructure:")
    console.print(f"   [cyan]superdeploy up -p {project}[/cyan]")
    console.print(f"\n3. Check status:")
    console.print(f"   [cyan]superdeploy status -p {project}[/cyan]")
    
    return  # Skip old instructions

    # Show exact commands with generated passwords
    if passwords:
        # Show for first service only (others will be same)
        if selected_services:
            service = selected_services[0]
            console.print(
                f"\n   # For each service repository ({', '.join(selected_services)}):"
            )
            console.print(f"   # Example for '{service}':")
            console.print(
                f'   [dim]gh secret set POSTGRES_USER -b "{project}_user" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set POSTGRES_PASSWORD -b "{passwords["POSTGRES_PASSWORD"]}" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set POSTGRES_DB -b "{project}_db" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set POSTGRES_HOST -b "postgres" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set POSTGRES_PORT -b "5432" -R {github_org}/{service}[/dim]'
            )
            console.print("")
            console.print(
                f'   [dim]gh secret set RABBITMQ_USER -b "{project}_user" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set RABBITMQ_PASSWORD -b "{passwords["RABBITMQ_PASSWORD"]}" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set RABBITMQ_HOST -b "rabbitmq" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set RABBITMQ_PORT -b "5672" -R {github_org}/{service}[/dim]'
            )
            console.print("")
            console.print(
                f'   [dim]gh secret set REDIS_PASSWORD -b "{passwords["REDIS_PASSWORD"]}" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set REDIS_HOST -b "redis" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set REDIS_PORT -b "6379" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f"\n   [dim]# Repeat for other services: {', '.join(selected_services[1:])}[/dim]"
            ) if len(selected_services) > 1 else None
    else:
        if selected_services:
            service = selected_services[0]
            console.print("\n   # For each service repository:")
            console.print(
                f"   [dim]gh secret set POSTGRES_PASSWORD -R {github_org}/{service}[/dim]"
            )
            console.print(
                f"   [dim]gh secret set RABBITMQ_PASSWORD -R {github_org}/{service}[/dim]"
            )
            console.print(
                f"   [dim]gh secret set REDIS_PASSWORD -R {github_org}/{service}[/dim]"
            )

    if passwords:
        console.print(
            f"\n   [dim]Generated passwords saved in: {project_dir}/.passwords.yml[/dim]"
        )

    console.print("\n2. Push your code:")
    console.print("   [dim]git push origin production[/dim]")

    console.print(
        "\n[green]ðŸš€ That's it! Deployment will happen automatically.[/green]"
    )


if __name__ == "__main__":
    init()
