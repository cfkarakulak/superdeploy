"""
Project initialization command with interactive setup
"""

import yaml
import click
from pathlib import Path
from datetime import datetime
from rich.console import Console
from cli.ui_components import show_header
from rich.prompt import Prompt, Confirm
from rich.table import Table
from jinja2 import Template

console = Console()


def get_available_addons():
    """Get list of available addons from the addons directory"""
    from cli.utils import get_project_root

    project_root = get_project_root()
    addons_dir = project_root / "addons"

    available = []

    if addons_dir.exists():
        for addon_dir in addons_dir.iterdir():
            if addon_dir.is_dir() and not addon_dir.name.startswith("."):
                # Check if addon.yml exists
                addon_yml = addon_dir / "addon.yml"
                if addon_yml.exists():
                    try:
                        with open(addon_yml) as f:
                            addon_meta = yaml.safe_load(f)
                            if addon_meta and "name" in addon_meta:
                                available.append(
                                    {
                                        "name": addon_meta["name"],
                                        "description": addon_meta.get(
                                            "description", ""
                                        ),
                                        "version": addon_meta.get("version", "latest"),
                                        "category": addon_meta.get("category", "other"),
                                    }
                                )
                    except (yaml.YAMLError, IOError):
                        # Skip invalid addons
                        continue

    return available


def get_used_subnets():
    """Get list of subnets already in use by other projects"""
    used_subnets = []

    # Use local projects directory
    from cli.utils import get_project_root

    project_root = get_project_root()
    projects_dir = project_root / "projects"

    if projects_dir.exists():
        from cli.core.config_loader import ConfigLoader

        config_loader = ConfigLoader(projects_dir)

        for project_name in config_loader.list_projects():
            try:
                project_config = config_loader.load_project(project_name)
                network_config = project_config.get_network_config()
                if network_config and "docker_subnet" in network_config:
                    used_subnets.append(network_config["docker_subnet"])
            except (FileNotFoundError, ValueError):
                continue

    return used_subnets


def find_next_subnet(used_subnets):
    """
    Find next available subnet using SubnetAllocator

    Note: This function is kept for backward compatibility but now uses
    SubnetAllocator for consistent subnet management across the system.
    """
    # Use SubnetAllocator for consistent subnet management
    # The used_subnets parameter is ignored as SubnetAllocator maintains its own state

    # Return a placeholder - actual allocation happens in config_loader
    # when project config is loaded
    return "auto"  # Will be replaced by SubnetAllocator


def render_template(template_path, context):
    """Render a template file with given context"""
    with open(template_path) as f:
        template = Template(f.read())

    # Render template with context
    return template.render(**context)


def generate_env_superdeploy(project, service, addons_dict):
    """Generate .env.superdeploy dynamically from addon metadata"""
    from cli.core.addon_loader import AddonLoader
    from cli.utils import get_project_root

    lines = [
        "# =============================================================================",
        "# SuperDeploy - Production Environment Overrides",
        "# =============================================================================",
        "# Auto-generated by: superdeploy init",
        "#",
        "# These values OVERRIDE your local .env in production deployment",
        "# Merged by GitHub Actions workflow (.env + .env.superdeploy)",
        "#",
        "# DO NOT EDIT MANUALLY - Regenerate with: superdeploy init",
        "# =============================================================================",
        "",
    ]

    # Load addons dynamically
    project_root = get_project_root()
    addons_dir = project_root / "addons"
    addon_loader = AddonLoader(addons_dir)

    try:
        # Build minimal config for addon loading
        config = {"project": project, "addons": addons_dict}
        loaded_addons = addon_loader.load_addons_for_project(config)

        # Generic iteration - no addon names!
        for addon_name, addon in loaded_addons.items():
            env_vars = addon.get_env_vars_for_template()
            if env_vars:
                lines.append("")
                lines.append(f"# {addon.get_description() or addon_name.title()}")
                for var_name in env_vars:
                    lines.append(f"{var_name}=${{{var_name}}}")
    except Exception as e:
        # Fallback to empty if addon loading fails
        console.print(f"[yellow]âš ï¸  Could not load addons: {e}[/yellow]")

    return "\n".join(lines)


def generate_workflow(project, service, addons_dict, github_org):
    """Generate GitHub Actions workflow dynamically from addon metadata"""
    from cli.core.addon_loader import AddonLoader
    from cli.core.template_merger import TemplateMerger
    from cli.utils import get_project_root

    # Load addons dynamically
    project_root = get_project_root()
    addons_dir = project_root / "addons"
    addon_loader = AddonLoader(addons_dir)
    template_merger = TemplateMerger()

    env_vars = []

    try:
        # Build minimal config for addon loading
        config = {"project": project, "addons": addons_dict}
        loaded_addons = addon_loader.load_addons_for_project(config)

        # Use existing TemplateMerger (already generic!)
        env_vars = template_merger.merge_workflow_env(loaded_addons)
    except Exception as e:
        # Fallback to empty if addon loading fails
        console.print(f"[yellow]âš ï¸  Could not load addons for workflow: {e}[/yellow]")

    env_section = "\n".join(env_vars)

    workflow = """name: Build and Deploy

on:
  push:
    branches:
      - production
  workflow_dispatch:

env:
  REGISTRY: docker.io
  IMAGE_NAME: {github_org}/{service}

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{{{ secrets.DOCKER_USERNAME }}}}
          password: ${{{{ secrets.DOCKER_TOKEN }}}}
      
      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{{{ env.REGISTRY }}}}/${{{{ env.IMAGE_NAME }}}}:${{{{ github.sha }}}}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Install age
        run: |
          curl -sL https://github.com/FiloSottile/age/releases/download/v1.1.1/age-v1.1.1-linux-amd64.tar.gz | tar xz
          sudo mv age/age /usr/local/bin/
          rm -rf age
      
      - name: Prepare environment bundle
        id: env_bundle
        env:
          # =============================================================================
          # CORE SERVICES (Auto-generated by superdeploy init)
          # =============================================================================
{env_section}
          
          # =============================================================================
          # APP-SPECIFIC SECRETS (Add your own below)
          # =============================================================================
          # Example:
          # {service_upper}_SECRET_KEY: ${{{{ secrets.{service_upper}_SECRET_KEY }}}}
          # STRIPE_API_KEY: ${{{{ secrets.STRIPE_API_KEY }}}}
        run: |
          # Merge .env files using shell
          cp .env /tmp/app.env 2>/dev/null || touch /tmp/app.env
          
          if [ -f .env.superdeploy ]; then
            while IFS='=' read -r key value || [ -n "$key" ]; do
              # Skip empty lines and comments
              [ -z "$key" ] && continue
              [[ "$key" =~ ^[[:space:]]*# ]] && continue
              
              # Expand ${{VAR}} syntax
              if [[ "$value" =~ ^\$\{{([^}}]+)\}}$ ]]; then
                var_name="${{BASH_REMATCH[1]}}"
                value="${{!var_name}}"
              fi
              
              # Update or append to merged env
              if grep -q "^${{key}}=" /tmp/app.env 2>/dev/null; then
                sed -i.bak "s|^${{key}}=.*|${{key}}=${{value}}|" /tmp/app.env && rm -f /tmp/app.env.bak
              else
                echo "${{key}}=${{value}}" >> /tmp/app.env
              fi
            done < .env.superdeploy
          fi
          
          # Encrypt with age public key
          cat /tmp/app.env | age -r "${{{{ secrets.AGE_PUBLIC_KEY }}}}" | base64 -w 0 > /tmp/encrypted.txt
          echo "encrypted=$(cat /tmp/encrypted.txt)" >> "$GITHUB_OUTPUT"
          rm -f /tmp/app.env /tmp/encrypted.txt
      
      - name: Connectivity check to Forgejo
        env:
          FORGEJO_BASE_URL: ${{{{ secrets.FORGEJO_BASE_URL }}}}
        run: |
          set -euo pipefail
          echo "Checking reachability of $FORGEJO_BASE_URL ..."
          # Try to reach Forgejo (5 second timeout)
          if curl -sS -I --max-time 5 --connect-timeout 5 "$FORGEJO_BASE_URL" 2>/dev/null; then
            echo "âœ“ Forgejo reachable"
          else
            echo "::warning::Forgejo base URL not reachable from GitHub runner."
            echo "This is expected if Forgejo is behind firewall/VPN."
            echo "Deployment will continue but may fail if Forgejo API is not accessible."
            echo "Tip: Check firewall rules, use public IP with port 443, or use self-hosted runner."
          fi
      
      - name: Trigger Forgejo deployment
        env:
          FORGEJO_PAT: ${{{{ secrets.FORGEJO_PAT }}}}
          FORGEJO_BASE_URL: ${{{{ secrets.FORGEJO_BASE_URL }}}}
          FORGEJO_ORG: ${{{{ secrets.FORGEJO_ORG }}}}
        run: |
          set -euo pipefail
          
          # Debug: Show PAT prefix (first 10 chars only)
          echo "PAT prefix: ${{FORGEJO_PAT:0:10}}..."
          echo "Base URL: $FORGEJO_BASE_URL"
          echo "Org: $FORGEJO_ORG"
          
          # Test PAT first
          echo "Testing PAT..."
          TEST_RESPONSE=$(curl -sS -i -H "Authorization: token $FORGEJO_PAT" "$FORGEJO_BASE_URL/api/v1/user")
          TEST_CODE=$(echo "$TEST_RESPONSE" | head -n1 | cut -d' ' -f2)
          echo "PAT test result: HTTP $TEST_CODE"
          
          if [[ "$TEST_CODE" != "200" ]]; then
            echo "::error::PAT is invalid (HTTP $TEST_CODE)"
            echo "$TEST_RESPONSE" | tail -5
            exit 1
          fi
          
          # Build JSON payload and trigger deployment
          RESPONSE=$(curl -sS -i -X POST \\
            --max-time 30 \\
            --connect-timeout 10 \\
            -H "Authorization: token $FORGEJO_PAT" \\
            -H "Content-Type: application/json" \\
            -d "{{\"ref\":\"master\",\"inputs\":{{\"image\":\"${{{{ env.REGISTRY }}}}/${{{{ env.IMAGE_NAME }}}}:${{{{ github.sha }}}}\",\"env_bundle\":\"${{{{ steps.env_bundle.outputs.encrypted }}}}\",\"git_sha\":\"${{{{ github.sha }}}}\"}}}}" \\
            "$FORGEJO_BASE_URL/api/v1/repos/$FORGEJO_ORG/superdeploy/actions/workflows/projects%2F{project}%2Fdeploy-{service}.yml/dispatches")
          
          HTTP_CODE=$(echo "$RESPONSE" | head -n1 | cut -d' ' -f2)
          BODY=$(echo "$RESPONSE" | tail -n1)
          
          echo "Response: $BODY"
          echo "HTTP Status: $HTTP_CODE"
          
          if [[ "$HTTP_CODE" =~ ^2[0-9][0-9]$ ]]; then
            echo "âœ“ Deployment triggered successfully"
          else
            echo "::error::Failed to trigger Forgejo deployment (HTTP $HTTP_CODE)"
            echo "::error::Response: $BODY"
            exit 1
          fi
""".format(
        github_org=github_org,
        service=service,
        env_section=env_section,
        service_upper=service.upper(),
        project=project,
    )

    return workflow


@click.command()
@click.option("--project", "-p", required=True, help="Project name")
@click.option(
    "--app", multiple=True, help="App in format name:path (e.g., api:../app-repos/api)"
)
@click.option("--subnet", help="Network subnet (e.g., 172.20.0.0/24)")
@click.option(
    "--no-interactive", is_flag=True, help="Non-interactive mode with defaults"
)
@click.option("--yes", "-y", is_flag=True, help="Skip confirmations")
def init(project, app, subnet, no_interactive, yes):
    """
    Initialize a new project (interactive wizard)

    Example:
        superdeploy init -p acme
        # Follow the wizard to configure your project
        # Then: superdeploy generate -p acme
    """
    show_header(
        title="Project Setup",
        subtitle="Creating new project with interactive wizard",
        project=project,
        show_logo=True,
        console=console,
    )

    from cli.utils import get_project_root

    project_root = get_project_root()
    projects_dir = project_root / "projects"
    project_dir = projects_dir / project

    # Check if project already exists
    if project_dir.exists():
        console.print(f"\n[red]âŒ Project '{project}' already exists![/red]")
        console.print(f"\n[dim]To modify:[/dim] {project_dir}/project.yml")
        console.print(
            f"[dim]Then run:[/dim] [cyan]superdeploy generate -p {project}[/cyan]\n"
        )
        return

    # Create project directory
    project_dir.mkdir(parents=True, exist_ok=True)

    # Determine mode
    interactive = not no_interactive

    # App selection with paths
    apps = {}  # {name: path}

    if app:
        # User provided apps via CLI
        for app_spec in app:
            if ":" not in app_spec:
                console.print(f"[red]âŒ Invalid format: {app_spec}[/red]")
                console.print(
                    "[dim]Use: --app name:path (e.g., --app api:../app-repos/api)[/dim]"
                )
                raise SystemExit(1)

            name, path = app_spec.split(":", 1)
            name = name.strip().lower()
            app_path = Path(path).expanduser().resolve()

            if not app_path.exists():
                console.print(f"[red]âŒ Path not found: {app_path}[/red]")
                raise SystemExit(1)

            apps[name] = app_path
    elif interactive:
        # Interactive app selection with paths
        console.print("\n[bold cyan]ðŸ“¦ Application Services[/bold cyan]")
        console.print("[dim]Add your app repositories (name + path)[/dim]")
        console.print("[dim]Example: api â†’ ../app-repos/api[/dim]")
        console.print("[dim]Press ENTER with empty name to finish[/dim]\n")

        service_num = 1

        while True:
            service_name = Prompt.ask(
                f"  Service {service_num} name",
                default=""
                if service_num > 2
                else ("api" if service_num == 1 else "dashboard"),
            )

            if not service_name or service_name.strip() == "":
                if service_num == 1:
                    console.print("[yellow]âš ï¸  At least one service required[/yellow]")
                    continue
                break

            service_name = service_name.strip().lower()

            # Validate service name
            if not service_name.replace("-", "").replace("_", "").isalnum():
                console.print(
                    "[yellow]âš ï¸  Invalid name (use letters, numbers, - or _)[/yellow]"
                )
                continue

            if service_name in apps:
                console.print(f"[yellow]âš ï¸  '{service_name}' already added[/yellow]")
                continue

            # Ask for path
            default_path = f"../app-repos/{service_name}"
            service_path = Prompt.ask(
                f"  Service {service_num} path", default=default_path
            )
            app_path = Path(service_path).expanduser().resolve()

            if not app_path.exists():
                console.print(f"[yellow]âš ï¸  Path not found: {app_path}[/yellow]")
                create = Confirm.ask("  Create directory?", default=False)
                if create:
                    app_path.mkdir(parents=True, exist_ok=True)
                    console.print(f"  [green]âœ“[/green] Created: {app_path}")
                else:
                    continue

            apps[service_name] = app_path
            console.print(f"  [green]âœ“[/green] Added: {service_name} â†’ {app_path}")
            service_num += 1

        console.print(f"\n  [cyan]Total services: {', '.join(apps.keys())}[/cyan]")
    else:
        # Default for non-interactive
        console.print("[red]âŒ No apps specified![/red]")
        console.print("[dim]Use --app flag or run without --no-interactive[/dim]")
        raise SystemExit(1)

    selected_services = list(apps.keys())

    # Network configuration
    used_subnets = get_used_subnets()

    if subnet:
        project_subnet = subnet
    elif interactive:
        console.print("\n[bold cyan]ðŸŒ Network Configuration[/bold cyan]")
        auto_subnet = Confirm.ask("  [cyan]Auto-assign subnet?[/cyan]", default=True)

        if auto_subnet:
            project_subnet = find_next_subnet(used_subnets)
            console.print(
                f"  [green]âœ“[/green] Auto-assigned: [cyan]{project_subnet}[/cyan]"
            )
        else:
            project_subnet = Prompt.ask(
                "  [cyan]Enter custom subnet[/cyan]", default="172.30.0.0/24"
            )
    else:
        project_subnet = find_next_subnet(used_subnets)

    # Core services selection (addon-based)
    available_addons = get_available_addons()

    # Filter to only show database, cache, queue addons (exclude caddy, monitoring, forgejo)
    available_addons_list = [
        (addon["name"], f"{addon['description']} ({addon['version']})")
        for addon in available_addons
        if addon["category"] in ["database", "cache", "queue"]
        and addon["name"] != "caddy"
    ]

    # Fallback if no addons found - use empty list, user can add later
    if not available_addons_list:
        console.print("[yellow]âš ï¸  No addons found in addons/ directory[/yellow]")
        available_addons_list = []

    # Set defaults for non-interactive mode: postgres, rabbitmq, caddy
    selected_addons = []
    if not interactive:
        # Non-interactive defaults
        default_addons = ["postgres", "rabbitmq", "caddy"]
        for addon_name, addon_desc in available_addons_list:
            if addon_name in default_addons:
                selected_addons.append(addon_name)
        # Always add caddy
        if "caddy" not in selected_addons:
            selected_addons.append("caddy")
    elif available_addons_list:
        # Interactive defaults
        default_addons = ["postgres", "rabbitmq", "redis", "caddy"]
        for addon_name, addon_desc in available_addons_list:
            if addon_name in default_addons:
                selected_addons.append(addon_name)

    if interactive:
        import inquirer

        console.print("\n[bold cyan]ðŸ”§ Infrastructure Addons[/bold cyan]")
        console.print("[dim]Use SPACE to select, ENTER to confirm[/dim]")
        console.print(
            "[dim]These services are shared by all apps (databases, queues, etc.)[/dim]"
        )
        console.print(
            f"[dim]Available: {len(available_addons_list)} addons (Caddy is always included)[/dim]\n"
        )

        questions = [
            inquirer.Checkbox(
                "services",
                message="Select addons",
                choices=[f"{name}: {desc}" for name, desc in available_addons_list],
                default=[
                    f"{name}: {desc}"
                    for name, desc in available_addons_list
                    if name in selected_addons
                ],
            ),
        ]

        answers = inquirer.prompt(questions)
        if answers and answers["services"]:
            # Extract service names from "name: description" format
            selected_addons = [
                choice.split(":")[0].strip() for choice in answers["services"]
            ]
        else:
            console.print("[yellow]âš ï¸  No services selected, using defaults[/yellow]")
            # Keep the defaults we calculated earlier

    # Always ensure Caddy is included (required for reverse proxy)
    if "caddy" not in selected_addons:
        selected_addons.append("caddy")

    # Password generation - always enabled (user can regenerate later)
    generate_passwords = True

    # GitHub Organization - removed, user will set in project.yml

    # Domain - empty by default (user can set in project.yml)
    project_domain = ""

    # SSL Email for Let's Encrypt (required for Caddy)
    ssl_email = ""
    if interactive:
        console.print("\n[bold cyan]ðŸ” SSL Configuration[/bold cyan]")
        console.print("[dim]Email for Let's Encrypt certificate notifications[/dim]")
        ssl_email = Prompt.ask(
            "  [cyan]SSL Email[/cyan]", default=f"admin@{project}.com"
        )
    else:
        # Non-interactive: use default
        ssl_email = f"admin@{project}.com"

    # Dynamic port assignments (no hardcoded service names!)
    base_external_port = 8000 + len(used_subnets) * 100  # Offset by 100 per project
    base_internal_port = 8000

    # Summary
    console.print("\n[bold cyan]ðŸ“‹ Summary:[/bold cyan]")
    console.print("â”" * 40)

    table = Table(
        title="Project Summary",
        show_header=False,
        box=None,
        title_justify="left",
        padding=(0, 1),
    )
    table.add_column("Property", style="dim")
    table.add_column("Value", style="bright_white")

    table.add_row("Project:", project)
    table.add_row("Services:", ", ".join(selected_services))
    table.add_row("Network:", project_subnet)
    table.add_row("Database:", "PostgreSQL 15")
    table.add_row("Queue:", "RabbitMQ 3.12")
    table.add_row("Cache:", "Redis 7")
    if project_domain:
        table.add_row("Domain:", project_domain)

    console.print(table)

    # Confirm
    if (
        interactive
        and not yes
        and not Confirm.ask("\n[bold]Create project?[/bold]", default=True)
    ):
        console.print("[yellow]Cancelled.[/yellow]")
        return

    # Build port assignments dynamically
    # Common service ports (can be overridden by user later)
    port_assignments = {}

    # Auto-assign ports generically (no hardcoded service names)
    # Start from base port and increment by 10 for each service
    for idx, service in enumerate(selected_services):
        port = base_external_port + (idx * 10)
        external_port = port
        internal_port = port

        port_assignments[service] = {
            "external": external_port,
            "internal": internal_port,
        }

    # Allocate subnets immediately during init
    from cli.subnet_allocator import SubnetAllocator

    allocator = SubnetAllocator()
    vpc_subnet = allocator.get_subnet(project)
    docker_subnet = allocator.get_docker_subnet(project)

    console.print("\n[cyan]ðŸ“¡ Network allocated:[/cyan]")
    console.print(f"  VPC Subnet: {vpc_subnet}")
    console.print(f"  Docker Subnet: {docker_subnet}")

    # Build temporary project config for validation
    # Note: Forgejo is managed globally by orchestrator, not per-project
    temp_config = {
        "project": project,
        "addons": {},
        "network": {
            "vpc_subnet": vpc_subnet,
            "docker_subnet": docker_subnet,
        },
        "apps": {
            app_name: (
                {
                    "path": str(app_path),
                    "port": port_assignments[app_name]["external"],
                }
                if port_assignments[app_name]["external"]
                == port_assignments[app_name]["internal"]
                else {
                    "path": str(app_path),
                    "external_port": port_assignments[app_name]["external"],
                    "internal_port": port_assignments[app_name]["internal"],
                }
            )
            for app_name, app_path in apps.items()
        },
    }

    # Add other selected addons
    for service in selected_addons:
        if service != "forgejo":  # Already added above
            temp_config["addons"][service] = {}

    # Validate configuration before creating files
    console.print("\n[dim]Validating configuration...[/dim]")
    from cli.core.validator import ValidationEngine, ValidationException
    from cli.core.addon_loader import AddonLoader

    validator = ValidationEngine(projects_dir)

    # Get available addon names for validation
    available_addon_names = {addon["name"] for addon in available_addons}

    # Load addons for validation (if addon system is available)
    try:
        addons_dir = project_root / "addons"
        if addons_dir.exists():
            addon_loader = AddonLoader(addons_dir)
            addons = addon_loader.load_addons_for_project(temp_config)
        else:
            # If addon system not available, use empty dict
            addons = {}
    except Exception as e:
        console.print(f"[yellow]âš  Could not load addons for validation: {e}[/yellow]")
        addons = {}

    # Run validation
    try:
        validator.validate_and_raise(
            temp_config, addons, project, available_addon_names
        )
        console.print("[dim]âœ“ Validation passed[/dim]")
    except ValidationException as e:
        console.print(f"\n[red]{e}[/red]")
        console.print("\n[yellow]âš  Fix validation errors before proceeding[/yellow]")
        console.print(
            "[dim]Hint: Use different subnet or ports to avoid conflicts[/dim]"
        )
        return

    # Create project structure
    console.print("\n[dim]Creating project structure...[/dim]")

    # Create project directory
    project_dir.mkdir(parents=True, exist_ok=True)

    # Template context for project.yml
    context = {
        "PROJECT": project,
        "CREATED_AT": datetime.now().isoformat(),
        "SUBNET": project_subnet,
    }

    # Build apps dict for template
    apps_dict = {}
    for idx, (app_name, app_path) in enumerate(apps.items()):
        apps_dict[app_name] = {
            "path": str(app_path),
            "vm": "core",
            "port": port_assignments[app_name]["external"],
        }

    # Build addons dict dynamically from addon metadata
    addon_versions = {addon["name"]: addon["version"] for addon in available_addons}
    addons_dict = {}

    # Note: Forgejo is managed globally by orchestrator, not per-project
    # Add selected addons dynamically
    for service in selected_addons:
        default_version = addon_versions.get(service, "latest")

        # Get addon metadata to determine config structure
        addon_meta = next((a for a in available_addons if a["name"] == service), None)

        if addon_meta:
            # Build config from addon metadata
            addon_config = {"version": default_version}

            # Add common fields based on env_vars in metadata
            env_vars = addon_meta.get("env_vars", [])
            for var in env_vars:
                if isinstance(var, dict):
                    var_name = var.get("name", "")
                    # Extract config key from var name (e.g., POSTGRES_USER -> user)
                    if "_USER" in var_name:
                        addon_config["user"] = f"{project}_user"
                    elif "_DATABASE" in var_name or "_DB" in var_name:
                        addon_config["database"] = f"{project}_db"

            addons_dict[service] = addon_config
        else:
            # Fallback if metadata not found
            addons_dict[service] = {"version": default_version}

    # Create project.yml manually (template has placeholders we need to replace)
    project_yml_content = f"""# =============================================================================
# {project} - Project Configuration
# =============================================================================
# Auto-generated by: superdeploy init -p {project}
# Edit this file, then run: superdeploy generate -p {project}
# =============================================================================

# Project Information
project:
  name: {project}
  description: {project} project
  created_at: {datetime.now().isoformat()}
  ssl_email: "{ssl_email}"  # For Let's Encrypt certificates

# =============================================================================
# Cloud Provider Configuration
# =============================================================================
cloud:
  # GCP Configuration
  gcp:
    project_id: "your-gcp-project-id"  # EDIT THIS
    region: "us-central1"
    zone: "us-central1-a"
  
  # SSH Configuration (for VM access)
  ssh:
    key_path: "~/.ssh/superdeploy_deploy"
    public_key_path: "~/.ssh/superdeploy_deploy.pub"
    user: "superdeploy"

# =============================================================================
# VMs (Infrastructure)
# =============================================================================
vms:
  core:
    count: 1
    machine_type: e2-medium
    disk_size: 20
    services:"""

    # Add shared services (databases, message queues) to core VM
    shared_services = [
        s
        for s in selected_addons
        if s in ["postgres", "rabbitmq", "redis", "mongodb", "elasticsearch"]
    ]
    for service in shared_services:
        project_yml_content += f"\n      - {service}"

    # Create a VM for each app (Caddy is automatically added by config_loader)
    for app_name in apps_dict.keys():
        project_yml_content += f"""
  {app_name}:
    count: 1
    machine_type: e2-small
    disk_size: 20
    services: []"""

    project_yml_content += """

# =============================================================================
# Addons Configuration
# =============================================================================
addons:
"""

    # Add all addons
    for service, config in addons_dict.items():
        project_yml_content += f"  {service}:\n"
        for key, value in config.items():
            project_yml_content += f'    {key}: "{value}"\n'

    project_yml_content += """
# =============================================================================
# Application Services
# =============================================================================
apps:
"""

    # Add apps - each app on its own VM
    for app_name, app_config in apps_dict.items():
        project_yml_content += f"  {app_name}:\n"
        project_yml_content += f"    path: {app_config['path']}\n"
        project_yml_content += f"    vm: {app_name}\n"  # VM name matches app name
        project_yml_content += f"    port: {app_config['port']}\n"
        # Add domain field
        if project_domain:
            project_yml_content += f'    domain: "{app_name}.{project_domain}"\n'
        else:
            project_yml_content += f'    domain: ""  # e.g., {app_name}.example.com\n'

    project_yml_content += f"""
# =============================================================================
# GitHub Configuration
# =============================================================================
github:
  organization: "your-github-org"  # EDIT THIS
  # Variables: GITHUB_TOKEN (from .env)

# =============================================================================
# Network Configuration
# =============================================================================
network:
  vpc_subnet: {vpc_subnet}
  docker_subnet: {docker_subnet}
"""

    # Write project.yml
    project_yml_path = project_dir / "project.yml"
    project_yml_path.write_text(project_yml_content)
    console.print(f"  [green]âœ“[/green] Created: {project_yml_path}")

    # Success message
    console.print("\n[bold green]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[/bold green]")
    console.print("[color(248)]Project initialized.[/color(248)]")
    console.print("[bold green]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[/bold green]")

    console.print(f"\n[cyan]ðŸ“„ Config saved to:[/cyan] {project_yml_path}")

    # Next steps
    console.print("\n[bold]Next steps:[/bold]")
    console.print(
        "  1. [dim]Generate deployment files:[/dim] [cyan]superdeploy generate -p {project}[/cyan]".format(
            project=project
        )
    )
    console.print(
        "  2. [dim]Deploy infrastructure:[/dim] [cyan]superdeploy up -p {project}[/cyan]".format(
            project=project
        )
    )
    console.print(
        "  3. [dim]Check status:[/dim] [cyan]superdeploy status -p {project}[/cyan]".format(
            project=project
        )
    )
    console.print()

    return  # Skip old instructions

    # Show exact commands with generated passwords
    if passwords:
        # Show for first service only (others will be same)
        if selected_services:
            service = selected_services[0]
            console.print(
                f"\n   # For each service repository ({', '.join(selected_services)}):"
            )
            console.print(f"   # Example for '{service}':")
            console.print(
                f'   [dim]gh secret set POSTGRES_USER -b "{project}_user" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set POSTGRES_PASSWORD -b "{passwords["POSTGRES_PASSWORD"]}" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set POSTGRES_DB -b "{project}_db" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set POSTGRES_HOST -b "postgres" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set POSTGRES_PORT -b "5432" -R {github_org}/{service}[/dim]'
            )
            console.print("")
            console.print(
                f'   [dim]gh secret set RABBITMQ_USER -b "{project}_user" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set RABBITMQ_PASSWORD -b "{passwords["RABBITMQ_PASSWORD"]}" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set RABBITMQ_HOST -b "rabbitmq" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set RABBITMQ_PORT -b "5672" -R {github_org}/{service}[/dim]'
            )
            console.print("")
            console.print(
                f'   [dim]gh secret set REDIS_PASSWORD -b "{passwords["REDIS_PASSWORD"]}" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set REDIS_HOST -b "redis" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f'   [dim]gh secret set REDIS_PORT -b "6379" -R {github_org}/{service}[/dim]'
            )
            console.print(
                f"\n   [dim]# Repeat for other services: {', '.join(selected_services[1:])}[/dim]"
            ) if len(selected_services) > 1 else None
    else:
        if selected_services:
            service = selected_services[0]
            console.print("\n   # For each service repository:")
            console.print(
                f"   [dim]gh secret set POSTGRES_PASSWORD -R {github_org}/{service}[/dim]"
            )
            console.print(
                f"   [dim]gh secret set RABBITMQ_PASSWORD -R {github_org}/{service}[/dim]"
            )
            console.print(
                f"   [dim]gh secret set REDIS_PASSWORD -R {github_org}/{service}[/dim]"
            )

    if passwords:
        console.print(
            f"\n   [dim]Generated passwords saved in: {project_dir}/.passwords.yml[/dim]"
        )

    console.print("\n2. Push your code:")
    console.print("   [dim]git push origin production[/dim]")

    console.print(
        "\n[green]ðŸš€ That's it! Deployment will happen automatically.[/green]"
    )


if __name__ == "__main__":
    init()
