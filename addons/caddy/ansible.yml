---
# Caddy Addon Deployment Tasks
# Handles deployment and certificate management for Caddy reverse proxy

# Check if this is orchestrator deployment
- name: Check if orchestrator deployment
  set_fact:
    is_orchestrator: "{{ project_name == 'orchestrator' }}"

# Include orchestrator-specific tasks if needed
- name: Include orchestrator-specific Caddy deployment
  include_tasks: "{{ addon_path }}/ansible.orchestrator.yml"
  when: is_orchestrator | bool

# Skip regular deployment for orchestrator
- name: Skip regular Caddy deployment for orchestrator
  meta: end_play
  when: is_orchestrator | bool

# Regular project Caddy deployment continues below
- name: Create {{ addon_name }} directories
  file:
    path: "{{ item }}"
    state: directory
    owner: "{{ superdeploy_user }}"
    group: "{{ superdeploy_group | default(superdeploy_user) }}"
    mode: '0755'
  loop:
    - "{{ addon_base_path }}/{{ addon_name }}"
    - "{{ addon_base_path }}/{{ addon_name }}/data"
    - "{{ addon_base_path }}/{{ addon_name }}/config"

- name: Render Caddyfile for {{ addon_name }}
  template:
    src: "{{ addon_path }}/Caddyfile.j2"
    dest: "{{ addon_base_path }}/{{ addon_name }}/Caddyfile"
    owner: "{{ superdeploy_user }}"
    group: "{{ superdeploy_group | default(superdeploy_user) }}"
    mode: '0644'
  register: caddyfile_result

# Note: docker-compose.yml is already rendered by orchestration/addon-deployer/tasks/render-templates.yml
# This keeps the deployment logic clean and focused on service-specific tasks

- name: Render {{ addon_name }} environment file
  template:
    src: "{{ addon_path }}/templates/caddy.env.j2"
    dest: "{{ addon_base_path }}/{{ addon_name }}/.env"
    owner: "{{ superdeploy_user }}"
    group: "{{ superdeploy_group | default(superdeploy_user) }}"
    mode: '0600'
  when: addon_path is defined and addon_path | length > 0

- name: Deploy {{ addon_name }} with intelligent cleanup
  shell:
    cmd: |
      set -e
      cd "${ADDON_BASE_PATH}/${ADDON_NAME}"
      
      echo "Starting cleanup for ${PROJECT_NAME}-${ADDON_NAME}..."
      
      # Phase 1: Stop via Docker Compose (graceful shutdown)
      echo "Phase 1: Stopping containers via Docker Compose..."
      docker compose --project-name "${PROJECT_NAME}-${ADDON_NAME}" down --remove-orphans --timeout 30 2>&1 || true
      
      # Phase 2: Wait for Docker daemon to sync
      echo "Phase 2: Waiting for Docker daemon to sync..."
      sleep 3
      
      # Phase 3: Aggressive cleanup with verification loop
      echo "Phase 3: Verifying all containers are removed..."
      for attempt in 1 2 3 4 5; do
        # Get ALL matching containers (running, stopped, exited)
        CONTAINER_IDS=$(docker ps -aq --filter "name=^${PROJECT_NAME}-${ADDON_NAME}$" 2>/dev/null || true)
        
        if [ -z "$CONTAINER_IDS" ]; then
          echo "✓ All containers removed successfully (attempt $attempt)"
          break
        fi
        
        echo "Attempt $attempt: Found remaining containers: $CONTAINER_IDS"
        
        # Force kill then remove
        for cid in $CONTAINER_IDS; do
          echo "  - Killing container: $cid"
          docker kill "$cid" 2>&1 || true
          sleep 1
          echo "  - Removing container: $cid"
          docker rm -f "$cid" 2>&1 || true
        done
        
        # Verify removal
        sleep 2
        REMAINING=$(docker ps -aq --filter "name=^${PROJECT_NAME}-${ADDON_NAME}$" 2>/dev/null | wc -l)
        
        if [ "$REMAINING" -eq 0 ]; then
          echo "✓ Cleanup successful after $attempt attempt(s)"
          break
        fi
        
        if [ $attempt -eq 5 ]; then
          echo "⚠ ERROR: Failed to remove all containers after 5 attempts"
          docker ps -a --filter "name=${PROJECT_NAME}-${ADDON_NAME}"
          exit 1
        fi
        
        echo "  Waiting before retry..."
        sleep 3
      done
      
      # Phase 4: Final sync and prune
      echo "Phase 4: Final cleanup..."
      docker container prune -f >/dev/null 2>&1 || true
      sleep 3
      
      # Final verification
      FINAL_CHECK=$(docker ps -aq --filter "name=^${PROJECT_NAME}-${ADDON_NAME}$" 2>/dev/null || true)
      if [ -n "$FINAL_CHECK" ]; then
        echo "⚠ ERROR: Containers still exist after cleanup!"
        docker ps -a --filter "name=${PROJECT_NAME}-${ADDON_NAME}"
        exit 1
      fi
      
      echo "✓ Cleanup completed successfully - ready for deployment"
      
      # Critical: Wait for Docker daemon to fully update its metadata
      # Without this, docker-compose may still see stale container references
      echo "Waiting for Docker daemon to sync metadata..."
      sleep 5
    executable: /bin/bash
  environment:
    PROJECT_NAME: "{{ project_name }}"
    ADDON_NAME: "{{ addon_name }}"
    ADDON_BASE_PATH: "{{ addon_base_path }}"
  become: yes
  register: caddy_cleanup_result
  changed_when: false

- name: Start {{ addon_name }} services (with explicit project name)
  community.docker.docker_compose_v2:
    project_name: "{{ project_name }}-{{ addon_name }}"
    project_src: "{{ addon_base_path }}/{{ addon_name }}"
    state: present
    pull: "always"
    recreate: "always"
    remove_orphans: true
  become: yes
  register: caddy_compose_result

- name: Wait for {{ addon_name }} container to start
  shell: sleep 5
  changed_when: false
  when: caddy_compose_result.changed

- name: Wait for {{ addon_name }} to be ready
  wait_for:
    host: localhost
    port: "{{ CADDY_ADMIN_PORT | default(2019) }}"
    delay: 2
    timeout: 60
    state: started

- name: Verify {{ addon_name }} admin API is accessible
  uri:
    url: "http://localhost:{{ CADDY_ADMIN_PORT | default(2019) }}/config/"
    method: GET
    status_code: 200
  register: caddy_health
  until: caddy_health.status == 200
  retries: 5
  delay: 3
  failed_when: false

- name: Verify {{ addon_name }} TLS certificate status
  uri:
    url: "http://localhost:{{ CADDY_ADMIN_PORT | default(2019) }}/config/apps/tls/certificates"
    method: GET
    status_code: 200
  register: caddy_certs
  failed_when: false

- name: Display {{ addon_name }} certificate information
  debug:
    msg: "Caddy TLS certificates: {{ caddy_certs.json | default('Not available') }}"
  when: 
    - caddy_certs is defined
    - caddy_certs.json is defined

- name: Ensure {{ addon_name }} certificate renewal is configured
  cron:
    name: "Check Caddy certificate renewal for {{ project_name }}"
    minute: "0"
    hour: "2"
    job: "docker exec {{ project_name }}-{{ addon_name }} caddy reload --config /etc/caddy/Caddyfile"
    user: "{{ superdeploy_user }}"

- name: Display {{ addon_name }} deployment status
  debug:
    msg: "Caddy is ready - HTTP on port {{ CADDY_HTTP_PORT | default(80) }}, HTTPS on port {{ CADDY_HTTPS_PORT | default(443) }}"
